{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import difflib\n",
    "\n",
    "import sys\n",
    "sys.path.append('../AJA')\n",
    "import AJA as aja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def compter_mots(phrase):\n",
    "    mots = phrase.split()  # Divisez la phrase en mots en utilisant les espaces comme d√©limiteurs\n",
    "    return len(mots)\n",
    "\n",
    "def calculate_similarity(text, neighbors, df):\n",
    "    max_similarity = 0.0\n",
    "    if isinstance(neighbors, list):\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor != []:\n",
    "                if isinstance(neighbor, int):\n",
    "                    neighbor_index = neighbor\n",
    "                else:\n",
    "                    neighbor_index = neighbor[0]\n",
    "                neighbor_text = df.iloc[neighbor_index]['text']\n",
    "                matcher = difflib.SequenceMatcher(None, text.split(), neighbor_text.split())\n",
    "                similarity = matcher.ratio()\n",
    "                max_similarity = max(max_similarity, similarity)\n",
    "    elif isinstance(neighbors, int):\n",
    "        # Handle the case where 'neighbors' is an integer directly\n",
    "        neighbor_index = neighbors\n",
    "        neighbor_text = df.iloc[neighbor_index]['text']\n",
    "        matcher = difflib.SequenceMatcher(None, text.split(), neighbor_text.split())\n",
    "        max_similarity = matcher.ratio()\n",
    "    return max_similarity\n",
    "\n",
    "\n",
    "\n",
    "def f(df_nodes, df_edges):\n",
    "\n",
    "    df = df_nodes.copy()\n",
    "\n",
    "    # sentence length normalized\n",
    "    df['sentence_length'] = df['text'].apply(lambda s: len(s.split()))\n",
    "    scaler = StandardScaler()\n",
    "    df['sentence_length'] = scaler.fit_transform(df['sentence_length'].values.reshape(-1, 1))\n",
    "\n",
    "    # speaker hot-one encoding\n",
    "    one_hot_encoded = pd.get_dummies(df['speaker_int'], prefix='speaker', dtype='int')\n",
    "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "\n",
    "    df['nb_mots'] = df['text'].apply(compter_mots)\n",
    "    df['nb_interrogations'] = df['text'].apply(lambda x: x.count('?'))\n",
    "    df['nb_occurences'] = df['text'].apply(lambda x: sum(x.split().count(mot) for mot in ['uh', 'um', 'okay', '<', 'ah', 'oh']))\n",
    "    df['nb_words_more_5'] = df['text'].apply(lambda x: sum(len(mot) > 5 and mot.lower() != '<vocalsound>' for mot in x.split()))\n",
    "\n",
    "    # Calcul de la colonne 'neighb'\n",
    "    df_edges_grouped = df_edges.groupby(['transcription', 'start'])['end'].apply(list).reset_index()\n",
    "    df = pd.merge(df, df_edges_grouped, how='left', left_on=['transcription', 'line'], right_on=['transcription', 'start'])\n",
    "    df = df.rename(columns={'end': 'neighb'})\n",
    "\n",
    "    # Calcul de la colonne 'similarities'\n",
    "    df['similarities'] = df.apply(lambda row: calculate_similarity(row['text'], row['neighb'],df), axis=1)\n",
    "\n",
    "    df = df.drop(['text', 'speaker_int', 'speaker_text', 'start', 'neighb'], axis=1)\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "def g(df):\n",
    "    new_df = pd.DataFrame({\n",
    "        'transcription': df['transcription'],\n",
    "        'start': df['end'],\n",
    "        'end': df['start'],\n",
    "        'type_int': 16 + df['type_int'],\n",
    "        'type_text': df['type_text'] + \"_reverse\"\n",
    "    })\n",
    "    result_df = pd.concat([df, new_df], ignore_index=True)\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      transcription  line  label    bert_0    bert_1    bert_2    bert_3  \\\n",
      "0           ES2002a     0      0 -0.057809 -0.085828 -0.035720 -0.011185   \n",
      "1           ES2002a     1      0 -0.054862  0.047607 -0.032626 -0.010949   \n",
      "2           ES2002a     2      1 -0.054665 -0.073837 -0.017161 -0.064276   \n",
      "3           ES2002a     3      0 -0.010416 -0.072719 -0.017206 -0.088992   \n",
      "4           ES2002a     4      0 -0.028654 -0.015151  0.095910 -0.059113   \n",
      "...             ...   ...    ...       ...       ...       ...       ...   \n",
      "72618       TS3012d  1278      0 -0.053178 -0.023260  0.015400  0.038154   \n",
      "72619       TS3012d  1279      0  0.003147  0.003671 -0.018923  0.019250   \n",
      "72620       TS3012d  1280      0 -0.129198  0.035191  0.014236  0.033648   \n",
      "72621       TS3012d  1281      0 -0.108031 -0.013967 -0.014813  0.032640   \n",
      "72622       TS3012d  1282      0 -0.146411  0.005653 -0.009107 -0.006575   \n",
      "\n",
      "         bert_4    bert_5    bert_6  ...  sentence_length  speaker_0  \\\n",
      "0      0.062363 -0.023545  0.061487  ...        -1.008131          1   \n",
      "1     -0.035741 -0.051808  0.052922  ...        -1.008131          1   \n",
      "2      0.004937  0.062475 -0.030765  ...         0.789302          1   \n",
      "3     -0.048035  0.051155  0.005855  ...        -0.558773          1   \n",
      "4      0.042067  0.033088 -0.070130  ...         1.088874          1   \n",
      "...         ...       ...       ...  ...              ...        ...   \n",
      "72618  0.066883 -0.110139 -0.013560  ...        -0.708559          0   \n",
      "72619 -0.008997  0.038625  0.104237  ...        -0.408987          0   \n",
      "72620  0.035818  0.028737  0.116457  ...        -0.858345          0   \n",
      "72621  0.068986 -0.020265  0.087994  ...        -0.408987          0   \n",
      "72622  0.086674  0.016706  0.111965  ...        -0.858345          0   \n",
      "\n",
      "       speaker_1  speaker_2  speaker_3  nb_mots  nb_interrogations  \\\n",
      "0              0          0          0        1                  0   \n",
      "1              0          0          0        1                  0   \n",
      "2              0          0          0       13                  0   \n",
      "3              0          0          0        4                  0   \n",
      "4              0          0          0       15                  0   \n",
      "...          ...        ...        ...      ...                ...   \n",
      "72618          1          0          0        3                  0   \n",
      "72619          1          0          0        5                  0   \n",
      "72620          1          0          0        2                  0   \n",
      "72621          0          0          1        5                  0   \n",
      "72622          1          0          0        2                  0   \n",
      "\n",
      "       nb_occurences  nb_words_more_5  similarities  \n",
      "0                  0                0      0.000000  \n",
      "1                  0                0      0.000000  \n",
      "2                  0                3      0.117647  \n",
      "3                  1                0      0.000000  \n",
      "4                  0                2      0.058824  \n",
      "...              ...              ...           ...  \n",
      "72618              0                1      0.000000  \n",
      "72619              0                2      0.285714  \n",
      "72620              0                0      0.000000  \n",
      "72621              0                0      0.148148  \n",
      "72622              0                0      0.000000  \n",
      "\n",
      "[72623 rows x 397 columns]\n",
      "      transcription  line    bert_0    bert_1    bert_2    bert_3    bert_4  \\\n",
      "0           ES2003a     0 -0.044312 -0.050093  0.019836 -0.025467  0.007840   \n",
      "1           ES2003a     1 -0.066844 -0.107671  0.001585 -0.037790 -0.075568   \n",
      "2           ES2003a     2 -0.072986  0.052575 -0.001435 -0.013834 -0.060743   \n",
      "3           ES2003a     3 -0.069117 -0.030910  0.073598 -0.066847 -0.036187   \n",
      "4           ES2003a     4 -0.085503 -0.080607  0.045568  0.049941  0.085909   \n",
      "...             ...   ...       ...       ...       ...       ...       ...   \n",
      "31021       TS3007d  1467 -0.035237 -0.044545  0.010157 -0.018947 -0.002187   \n",
      "31022       TS3007d  1468  0.011374 -0.050256 -0.044846 -0.061941 -0.042007   \n",
      "31023       TS3007d  1469 -0.009817  0.014421  0.066075 -0.006914  0.001343   \n",
      "31024       TS3007d  1470 -0.029034  0.004965  0.001875  0.015295 -0.050566   \n",
      "31025       TS3007d  1471 -0.146411  0.005653 -0.009107 -0.006575  0.086674   \n",
      "\n",
      "         bert_5    bert_6    bert_7  ...  sentence_length  speaker_0  \\\n",
      "0     -0.022715 -0.003443  0.070615  ...        -0.709542          1   \n",
      "1      0.088113  0.002547 -0.017422  ...        -0.130212          1   \n",
      "2     -0.052947  0.042082  0.006406  ...        -0.854375          1   \n",
      "3     -0.088590  0.124545  0.038046  ...        -0.419877          1   \n",
      "4      0.002567  0.040710  0.009796  ...        -0.130212          1   \n",
      "...         ...       ...       ...  ...              ...        ...   \n",
      "31021  0.013901 -0.010772 -0.112388  ...         0.593951          0   \n",
      "31022  0.026962  0.041946 -0.068002  ...        -0.419877          0   \n",
      "31023 -0.031755  0.156677 -0.006366  ...         0.449118          1   \n",
      "31024  0.025322  0.066461 -0.082718  ...        -0.275045          1   \n",
      "31025  0.016706  0.111965 -0.048977  ...        -0.854375          1   \n",
      "\n",
      "       speaker_1  speaker_2  speaker_3  nb_mots  nb_interrogations  \\\n",
      "0              0          0          0        3                  0   \n",
      "1              0          0          0        7                  0   \n",
      "2              0          0          0        2                  0   \n",
      "3              0          0          0        5                  0   \n",
      "4              0          0          0        7                  0   \n",
      "...          ...        ...        ...      ...                ...   \n",
      "31021          0          1          0       12                  0   \n",
      "31022          1          0          0        5                  0   \n",
      "31023          0          0          0       11                  1   \n",
      "31024          0          0          0        6                  0   \n",
      "31025          0          0          0        2                  0   \n",
      "\n",
      "       nb_occurences  nb_words_more_5  similarities  \n",
      "0                  0                0      0.400000  \n",
      "1                  0                0      0.000000  \n",
      "2                  0                0      0.285714  \n",
      "3                  0                2      0.166667  \n",
      "4                  0                2      0.142857  \n",
      "...              ...              ...           ...  \n",
      "31021              1                4      0.307692  \n",
      "31022              0                1      0.000000  \n",
      "31023              0                0      0.095238  \n",
      "31024              0                3      0.000000  \n",
      "31025              0                0      0.000000  \n",
      "\n",
      "[31026 rows x 396 columns]\n"
     ]
    }
   ],
   "source": [
    "train_graphs, validation_graphs, test_graphs = aja.get_graphs(f, g, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[471, 394], edge_index=[32], y=[471])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on check la forme des input\n",
    "train_graphs['TS3008a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiChannelsGCN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, channels, input_dim, post_conv_dim, output_dim, identity=False):\n",
    "        super(MultiChannelsGCN, self).__init__()\n",
    "        self.identity = identity\n",
    "        self.channels = channels\n",
    "        self.input_dim = input_dim\n",
    "        self.post_conv_dim = post_conv_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.GCN = nn.ModuleList([GCNConv(input_dim, post_conv_dim) for _ in range(channels)])\n",
    "        if identity:\n",
    "            self.dense = nn.Linear(post_conv_dim * (channels + 1), output_dim)\n",
    "            self.denseID = nn.Linear(input_dim, post_conv_dim)\n",
    "        else:\n",
    "            self.dense = nn.Linear(post_conv_dim * channels, output_dim)\n",
    "\n",
    "    def forward(self, nodes, edges):\n",
    "        X = []\n",
    "        for k in range(self.channels):\n",
    "            if len(edges[k]) == 0:\n",
    "                x = torch.zeros(nodes.shape[0], self.post_conv_dim)\n",
    "            else:\n",
    "                x = F.relu(self.GCN[k](nodes, edges[k]))\n",
    "            X.append(x)\n",
    "        if self.identity:\n",
    "            X.append(F.relu(self.denseID(nodes)))\n",
    "        concat = torch.cat(X, dim=1)\n",
    "        return F.relu(self.dense(concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on d√©finie son plus beau mod√®le\n",
    "\n",
    "class NodeClassifier(torch.nn.Module):\n",
    "    def __init__(self, channels, input_dim):\n",
    "        super(NodeClassifier, self).__init__()\n",
    "        self.threshold = 0.5\n",
    "        self.GCN1 = MultiChannelsGCN(channels, input_dim, 50, 20, identity=True)\n",
    "        self.dropout = nn.Dropout(0.3)  # Couche de dropout\n",
    "        self.GCN2 = MultiChannelsGCN(channels, input_dim, 50, 20, identity=True)\n",
    "        self.dense1 = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        nodes, edges = data.x, data.edge_index\n",
    "        \n",
    "        x = self.GCN1(nodes, edges)\n",
    "        x = self.dense1(x)\n",
    "        return x\n",
    "\n",
    "    def set_threshold(self, t):\n",
    "        self.threshold = t\n",
    "\n",
    "    def predict(self, graph):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(graph)\n",
    "            predictions = torch.sigmoid(logits)\n",
    "        return np.array((predictions > self.threshold).int()).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Charger l'extension autoreload\n",
    "%load_ext autoreload\n",
    "\n",
    "# Configurer autoreload pour recharger tous les modules avant l'ex√©cution de chaque cellule\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Epoch 000 -\n",
      "Loss: 56.4338\n",
      "F1 train: 0.5605460008205813\n",
      "F1 valid: 0.5520281502263191\n",
      "\n",
      "- Epoch 001 -\n",
      "Loss: 47.0669\n",
      "F1 train: 0.5696155457803415\n",
      "F1 valid: 0.5540634591539471\n",
      "\n",
      "- Epoch 002 -\n",
      "Loss: 45.9772\n",
      "F1 train: 0.5780528928296496\n",
      "F1 valid: 0.5576722750156237\n",
      "\n",
      "- Epoch 003 -\n",
      "Loss: 45.1001\n",
      "F1 train: 0.584154089186946\n",
      "F1 valid: 0.5601721127975796\n",
      "\n",
      "- Epoch 004 -\n",
      "Loss: 44.3326\n",
      "F1 train: 0.590284752021169\n",
      "F1 valid: 0.5604700192368527\n",
      "\n",
      "- Epoch 005 -\n",
      "Loss: 43.2783\n",
      "F1 train: 0.6023650869515703\n",
      "F1 valid: 0.5636195693876591\n",
      "\n",
      "- Epoch 006 -\n",
      "Loss: 42.2746\n",
      "F1 train: 0.6083681088216312\n",
      "F1 valid: 0.5633640940667487\n",
      "\n",
      "- Epoch 007 -\n",
      "Loss: 40.7868\n",
      "F1 train: 0.6203666952158532\n",
      "F1 valid: 0.5677606396134969\n",
      "\n",
      "- Epoch 008 -\n",
      "Loss: 39.2912\n",
      "F1 train: 0.631534864518404\n",
      "F1 valid: 0.5674072124757327\n",
      "\n",
      "- Epoch 009 -\n",
      "Loss: 37.9110\n",
      "F1 train: 0.6393183489085897\n",
      "F1 valid: 0.5693207386504503\n",
      "\n",
      "- Epoch 010 -\n",
      "Loss: 35.9957\n",
      "F1 train: 0.6498322186041241\n",
      "F1 valid: 0.5601782195885646\n",
      "\n",
      "- Epoch 011 -\n",
      "Loss: 34.3716\n",
      "F1 train: 0.6577156132404242\n",
      "F1 valid: 0.5619679111181859\n",
      "\n",
      "- Epoch 012 -\n",
      "Loss: 32.7441\n",
      "F1 train: 0.6656802301659213\n",
      "F1 valid: 0.5581134384627727\n",
      "\n",
      "- Epoch 013 -\n",
      "Loss: 31.5473\n",
      "F1 train: 0.6886254746940726\n",
      "F1 valid: 0.5530558992070851\n",
      "\n",
      "- Epoch 014 -\n",
      "Loss: 30.0034\n",
      "F1 train: 0.696227188955001\n",
      "F1 valid: 0.5580293591700773\n",
      "\n",
      "- Epoch 015 -\n",
      "Loss: 28.6859\n",
      "F1 train: 0.7096585149288364\n",
      "F1 valid: 0.5526035422767426\n",
      "\n",
      "- Epoch 016 -\n",
      "Loss: 29.8599\n",
      "F1 train: 0.6958139743641858\n",
      "F1 valid: 0.5487712421766656\n",
      "\n",
      "- Epoch 017 -\n",
      "Loss: 30.5303\n",
      "F1 train: 0.6884382596131385\n",
      "F1 valid: 0.5511870592268606\n",
      "\n",
      "- Epoch 018 -\n",
      "Loss: 31.1967\n",
      "F1 train: 0.6781553850550054\n",
      "F1 valid: 0.5546109087385268\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb Cellule 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# on entraine !\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     loss \u001b[39m=\u001b[39m aja\u001b[39m.\u001b[39;49mtrain(model, train_graphs, optimizer, criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m- Epoch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m03d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoss:\u001b[39m\u001b[39m'\u001b[39m,  \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/X/INF554/AJA/INF554-AJA/Alice/../AJA/AJA.py:229\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_graphs, optimizer, criterion)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_graphs\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    228\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()  \u001b[39m# Clear gradients.\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m     out \u001b[39m=\u001b[39m model(data)  \u001b[39m# Perform a single forward pass.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     loss \u001b[39m=\u001b[39m criterion(out\u001b[39m.\u001b[39mfloat(), data\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))  \u001b[39m# Compute the loss solely based on the training nodes.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     loss\u001b[39m.\u001b[39mbackward()  \u001b[39m# Derive gradients.\u001b[39;00m\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb Cellule 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     nodes, edges \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mGCN1(nodes, edges)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb Cellule 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(nodes\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_conv_dim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mGCN[k](nodes, edges[k]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     X\u001b[39m.\u001b[39mappend(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/complex_NN_alice.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39midentity:\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:244\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    241\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x)\n\u001b[1;32m    243\u001b[0m \u001b[39m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, edge_weight\u001b[39m=\u001b[39;49medge_weight,\n\u001b[1;32m    245\u001b[0m                      size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     out \u001b[39m=\u001b[39m out \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:480\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         aggr_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 480\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate(out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49maggr_kwargs)\n\u001b[1;32m    482\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    483\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (aggr_kwargs, ), out)\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:604\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maggregate\u001b[39m(\u001b[39mself\u001b[39m, inputs: Tensor, index: Tensor,\n\u001b[1;32m    592\u001b[0m               ptr: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    593\u001b[0m               dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    594\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[39m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[39m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 604\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggr_module(inputs, index, ptr\u001b[39m=\u001b[39;49mptr, dim_size\u001b[39m=\u001b[39;49mdim_size,\n\u001b[1;32m    605\u001b[0m                             dim\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim)\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch_geometric/experimental.py:115\u001b[0m, in \u001b[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[39m'\u001b[39m\u001b[39mdisable_dynamic_shapes\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    117\u001b[0m     \u001b[39mfor\u001b[39;00m required_arg \u001b[39min\u001b[39;00m required_args:\n\u001b[1;32m    118\u001b[0m         index \u001b[39m=\u001b[39m required_args_pos[required_arg]\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:125\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m     dim_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmax()) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x, index\u001b[39m=\u001b[39;49mindex, ptr\u001b[39m=\u001b[39;49mptr, dim_size\u001b[39m=\u001b[39;49mdim_size,\n\u001b[1;32m    126\u001b[0m                             dim\u001b[39m=\u001b[39;49mdim, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    127\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    128\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch_geometric/nn/aggr/basic.py:22\u001b[0m, in \u001b[0;36mSumAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m             ptr: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m             dim: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduce(x, index, ptr, dim_size, dim, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:176\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[39mreturn\u001b[39;00m segment(x, ptr, reduce\u001b[39m=\u001b[39mreduce)\n\u001b[1;32m    175\u001b[0m \u001b[39massert\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[39mreturn\u001b[39;00m scatter(x, index, dim, dim_size, reduce)\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch_geometric/utils/scatter.py:70\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39madd\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     69\u001b[0m     index \u001b[39m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39;49mnew_zeros(size)\u001b[39m.\u001b[39mscatter_add_(dim, index, src)\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     73\u001b[0m     count \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# on instancie le mod√®le\n",
    "model = NodeClassifier(32,394)\n",
    "\n",
    "# on d√©finie la fonction de perte et l'optimiseur\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "alpha = 0.2  # Param√®tre de pond√©ration (ajustez selon votre cas)\n",
    "gamma = 5  # Param√®tre de focalit√© (ajustez selon votre cas)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor((1 - alpha) / alpha), reduction='mean')\n",
    "\n",
    "\n",
    "model.set_threshold(0.59)\n",
    "\n",
    "# on entraine !\n",
    "\n",
    "for epoch in range(20):\n",
    "    loss = aja.train(model, train_graphs, optimizer, criterion)\n",
    "    print('- Epoch', f'{epoch:03d}', '-')\n",
    "    print('Loss:',  f'{loss:.4f}')\n",
    "    f1_train = aja.f1_score_moyen(model, train_graphs)\n",
    "    f1_valid = aja.f1_score_moyen(model, validation_graphs)\n",
    "    print('F1 train:', f1_train)\n",
    "    print('F1 valid:', f1_valid)\n",
    "    torch.save(model.state_dict(), \"training_states/\"+str(epoch) + \".pth\")\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# on peut revenir √† un mod√®le interm√©diaire pour √©viter l'overfitting\n",
    "epoch_opt = 21\n",
    "model.load_state_dict(torch.load(\"training_states/\"+str(epoch_opt)+\".pth\"))\n",
    "\n",
    "T = np.linspace(0.6,0.9,10)\n",
    "f1s = []\n",
    "for t in T:\n",
    "    model.set_threshold(t)\n",
    "    f1_valid = aja.f1_score_moyen(model, validation_graphs)\n",
    "    f1s.append(f1_valid)\n",
    "\n",
    "plt.plot(T, f1s)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quand on est content on fait une submission !\n",
    "model.set_threshold(0.73)\n",
    "aja.make_test_csv_submission(model, test_graphs, 'alice-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
