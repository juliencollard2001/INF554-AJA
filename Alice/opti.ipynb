{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegorge/INF554/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import difflib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import sys\n",
    "sys.path.append('../AJA')\n",
    "import AJA as aja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def calculate_similarity(text, neighbors, df):\n",
    "    max_similarity = 0.0\n",
    "    if isinstance(neighbors, list):\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor != []:\n",
    "                if isinstance(neighbor, int):\n",
    "                    neighbor_index = neighbor\n",
    "                else:\n",
    "                    neighbor_index = neighbor[0]\n",
    "                neighbor_text = df.iloc[neighbor_index]['text']\n",
    "                matcher = difflib.SequenceMatcher(None, text.split(), neighbor_text.split())\n",
    "                similarity = matcher.ratio()\n",
    "                max_similarity = max(max_similarity, similarity)\n",
    "    elif isinstance(neighbors, int):\n",
    "        # Handle the case where 'neighbors' is an integer directly\n",
    "        neighbor_index = neighbors\n",
    "        neighbor_text = df.iloc[neighbor_index]['text']\n",
    "        matcher = difflib.SequenceMatcher(None, text.split(), neighbor_text.split())\n",
    "        max_similarity = matcher.ratio()\n",
    "    return max_similarity\n",
    "\n",
    "def f(df_nodes, df_edges):\n",
    "\n",
    "    df = df_nodes\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # sentence length normalized\n",
    "    df['sentence_length'] = df['text'].apply(lambda s: len(s.split()))\n",
    "    df['sentence_length'] = scaler.fit_transform(df['sentence_length'].values.reshape(-1, 1))\n",
    "\n",
    "    # speaker hot-one encoding\n",
    "    one_hot_encoded = pd.get_dummies(df['speaker_int'], prefix='speaker')\n",
    "    df = df.drop('speaker_int', axis=1)\n",
    "    df = df.drop('speaker_text', axis=1)\n",
    "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "    \n",
    "    # TFIDF\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['text'])\n",
    "    df['min_tfidf'] = tfidf_matrix.min(axis=1).toarray().flatten()\n",
    "    df['min_tfidf'] = scaler.fit_transform(df['min_tfidf'].values.reshape(-1, 1))\n",
    "    \n",
    "    #Text analysis\n",
    "    df['nb_occurences'] = df['text'].apply(lambda x: sum(x.split().count(mot) for mot in ['uh', 'um', 'okay', '<', 'ah', 'oh']))\n",
    "    df['nb_occurences'] = scaler.fit_transform(df['nb_occurences'].values.reshape(-1,1))\n",
    "    \n",
    "    df['nb_words_more_7'] = df['text'].apply(lambda x: sum(len(mot) > 7 and mot.lower() != '<vocalsound>' for mot in x.split()))\n",
    "    df['nb_words_more_7'] = scaler.fit_transform(df['nb_words_more_7'].values.reshape(-1,1))\n",
    "    \n",
    "    # Calcul de la colonne 'neighb'\n",
    "    df_edges_grouped = df_edges.groupby(['transcription', 'start'])['end'].apply(list).reset_index()\n",
    "    df = pd.merge(df, df_edges_grouped, how='left', left_on=['transcription', 'line'], right_on=['transcription', 'start'])\n",
    "    df = df.rename(columns={'end': 'neighb'})\n",
    "\n",
    "    # Calcul de la colonne 'similarities'\n",
    "    df['similarities'] = df.apply(lambda row: calculate_similarity(row['text'], row['neighb'],df), axis=1)\n",
    "    df['similarities'] = scaler.fit_transform(df['similarities'].values.reshape(-1,1))\n",
    "\n",
    "    # Calcul de la colonne 'nb_neighb'\n",
    "    df['nb_neighb'] = df['neighb'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    df['nb_neighb'] = scaler.fit_transform(df['nb_neighb'].values.reshape(-1, 1))\n",
    "\n",
    "    df = df.drop(['text','start', 'neighb'], axis=1)\n",
    "                    \n",
    "    return df\n",
    "\n",
    "def g(df):\n",
    "    new_df = pd.DataFrame({\n",
    "        'transcription': df['transcription'],\n",
    "        'start': df['end'],\n",
    "        'end': df['start'],\n",
    "        'type_int': 16 + df['type_int'],\n",
    "        'type_text': df['type_text'] + \"_reverse\"\n",
    "    })\n",
    "    result_df = pd.concat([df, new_df], ignore_index=True)\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graphs, validation_graphs, test_graphs = aja.get_graphs(f, g, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiChannelsGCN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, channels, input_dim, post_conv_dim, output_dim, identity=False):\n",
    "        super(MultiChannelsGCN, self).__init__()\n",
    "        self.identity = identity\n",
    "        self.channels = channels\n",
    "        self.input_dim = input_dim\n",
    "        self.post_conv_dim = post_conv_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.GCN = nn.ModuleList([GCNConv(input_dim, post_conv_dim) for _ in range(channels)])\n",
    "        if identity:\n",
    "            self.dense = nn.Linear(post_conv_dim * (channels + 1), output_dim)\n",
    "            self.denseID = nn.Linear(input_dim, post_conv_dim)\n",
    "        else:\n",
    "            self.dense = nn.Linear(post_conv_dim * channels, output_dim)\n",
    "\n",
    "    def forward(self, nodes, edges):\n",
    "        X = []\n",
    "        for k in range(self.channels):\n",
    "            if len(edges[k]) == 0:\n",
    "                x = torch.zeros(nodes.shape[0], self.post_conv_dim)\n",
    "            else:\n",
    "                x = F.relu(self.GCN[k](nodes, edges[k]))\n",
    "            X.append(x)\n",
    "        if self.identity:\n",
    "            X.append(F.relu(self.denseID(nodes)))\n",
    "        concat = torch.cat(X, dim=1)\n",
    "        return F.relu(self.dense(concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on définie son plus beau modèle\n",
    "\n",
    "class NodeClassifier(torch.nn.Module):\n",
    "    def __init__(self, channels, input_dim):\n",
    "        super(NodeClassifier, self).__init__()\n",
    "        self.threshold = 0.5\n",
    "        self.GCN1 = MultiChannelsGCN(channels, input_dim, 50, 20, identity=True)\n",
    "        self.dropout = nn.Dropout(0.02956182281427211)  # Couche de dropout \n",
    "        self.dense1 = nn.Linear(20,1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        nodes, edges = data.x, data.edge_index\n",
    "        \n",
    "        x = self.GCN1(nodes, edges)\n",
    "        x = self.dense1(x)\n",
    "        return x\n",
    "\n",
    "    def set_threshold(self, t):\n",
    "        self.threshold = t\n",
    "\n",
    "    def predict(self, graph): #version sans threshold\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(graph)\n",
    "        return np.array((logits > 0.5).int()).flatten()\n",
    "    \n",
    "    '''def predict(self, graph): #version avec threshold\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(graph)\n",
    "            predictions = torch.sigmoid(logits)\n",
    "        return np.array((predictions > self.threshold).int()).flatten()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger l'extension autoreload\n",
    "%load_ext autoreload\n",
    "\n",
    "# Configurer autoreload pour recharger tous les modules avant l'exécution de chaque cellule\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_features = train_graphs['ES2002a'].x.shape[1]\n",
    "N_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Epoch 000 -\n",
      "Loss: 0.8477\n",
      "F1 train: 0.5648616848459262\n",
      "F1 valid: 0.5870692280555174\n",
      "\n",
      "- Epoch 001 -\n",
      "Loss: 0.7653\n",
      "F1 train: 0.5770290060701599\n",
      "F1 valid: 0.6010289687373077\n",
      "\n",
      "- Epoch 002 -\n",
      "Loss: 0.7433\n",
      "F1 train: 0.5905178454573431\n",
      "F1 valid: 0.6186642208050149\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the instantiation of the model outside the training loop\n",
    "model = NodeClassifier(32, N_features)\n",
    "#model.set_threshold(0.59)\n",
    "model_name='test'\n",
    "\n",
    "# Move the model and data to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Use DataLoader to create batches of data\n",
    "#train_loader = DataLoader(list(train_graphs.values()), batch_size=1, shuffle=True)\n",
    "#N_train = len(train_loader)\n",
    "\n",
    "train_loader = DataLoader(list(train_graphs.values()) + list(validation_graphs.values()), batch_size=1, shuffle=False)\n",
    "N_train = len(train_loader)\n",
    "\n",
    "validation_loader = DataLoader(list(validation_graphs.values()), batch_size=1, shuffle=False)\n",
    "N_validation = len(validation_loader)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "alpha = 0.15730642604852357\n",
    "gamma = 9.760602307411109\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor((1 - alpha) / alpha), reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002272131994333311)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Train the model\n",
    "best_f1_score = 0\n",
    "for epoch in range(3):\n",
    "    print('- Epoch', f'{epoch:03d}', '-')\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data).squeeze()\n",
    "        loss = criterion(output, data.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    average_loss = total_loss / N_train\n",
    "    print('Loss:', f'{average_loss:.4f}')    \n",
    "\n",
    "    # Evaluate the model on the training set\n",
    "\n",
    "    model.eval()\n",
    "    f1_moyen_train = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        y_pred = model.predict(data)\n",
    "        y_true = data.y.cpu().numpy()\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        f1_moyen_train += f1\n",
    "    f1_moyen_train /= N_train\n",
    "    print('F1 train:', f1_moyen_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    f1_moyen_valid = 0\n",
    "    for data in validation_loader:\n",
    "        data = data.to(device)\n",
    "        y_pred = model.predict(data)\n",
    "        y_true = data.y.cpu().numpy()\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        f1_moyen_valid += f1\n",
    "    f1_moyen_valid /= N_validation\n",
    "    print('F1 valid:', f1_moyen_valid)\n",
    "\n",
    "    # callbacks ou autre\n",
    "    if f1_moyen_valid > best_f1_score:\n",
    "        torch.save(model.state_dict(), \"training_states/\" + model_name + \"-best.pth\")\n",
    "    else:\n",
    "        optimizer.param_groups[0]['lr'] /= 2\n",
    "        print('Learning rate reduced to:', optimizer.param_groups[0]['lr'])\n",
    "    print('')\n",
    "\n",
    "model.load_state_dict(torch.load(\"training_states/\" + model_name + \"-best.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.linspace(0.4,0.6,10)\n",
    "f1s = []\n",
    "for t in T:\n",
    "    model.set_threshold(t)\n",
    "    f1_valid = aja.f1_score_moyen(model, validation_graphs)\n",
    "    f1s.append(f1_valid)\n",
    "\n",
    "plt.plot(T, f1s)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quand on est content on fait une submission !\n",
    "#model.set_threshold(0.59) #on choisit le threshold adapté\n",
    "aja.make_test_csv_submission(model, test_graphs, 'ajout_alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:10<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/opti.ipynb Cellule 11\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/opti.ipynb#X30sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mf1_moyen_valid  \u001b[39m# Hyperopt minimise la fonction, donc nous utilisons -F1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/opti.ipynb#X30sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# Utiliser l'algorithme TPE pour l'optimisation bayésienne\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/opti.ipynb#X30sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m best \u001b[39m=\u001b[39m fmin(fn\u001b[39m=\u001b[39;49mobjective, space\u001b[39m=\u001b[39;49mspace, algo\u001b[39m=\u001b[39;49mtpe\u001b[39m.\u001b[39;49msuggest, max_evals\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/opti.ipynb#X30sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Afficher les meilleurs hyperparamètres trouvés\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/opti.ipynb#X30sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMeilleurs hyperparamètres:\u001b[39m\u001b[39m\"\u001b[39m, best)\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "\u001b[1;32m/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/opti.ipynb Cellule 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/opti.ipynb#X30sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/opti.ipynb#X30sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, data\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/opti.ipynb#X30sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/opti.ipynb#X30sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicegorge/Desktop/X/INF554/AJA/INF554-AJA/Alice/opti.ipynb#X30sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/INF554/miniconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "# Définir les hyperparamètres à optimiser\n",
    "space = {\n",
    "    'lr': hp.loguniform('lr', np.log(0.0001), np.log(0.1)),\n",
    "    'alpha': hp.uniform('alpha', 0.1, 0.9),\n",
    "    'gamma': hp.uniform('gamma', 1, 20),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0, 0.5),\n",
    "    'epochs': hp.choice('epochs', [5, 10, 15, 20])\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    # Convertir 'epochs' en int car hp.choice retourne un index\n",
    "    params['epochs'] = int(params['epochs'])\n",
    "\n",
    "    # Instancier le modèle avec les hyperparamètres actuels\n",
    "    model = NodeClassifier(32, N_features)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "    # Entraîner le modèle\n",
    "    for epoch in range(params['epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze()\n",
    "            loss = criterion(output, data.y.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        average_loss = total_loss / N_train\n",
    "\n",
    "    # Évaluer le modèle sur l'ensemble de validation\n",
    "    model.eval()\n",
    "    f1_moyen_valid = 0\n",
    "    for data in validation_loader:\n",
    "        data = data.to(device)\n",
    "        y_pred = model.predict(data)\n",
    "        y_true = data.y.cpu().numpy()\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        f1_moyen_valid += f1\n",
    "    f1_moyen_valid /= N_validation\n",
    "\n",
    "    return -f1_moyen_valid  # Hyperopt minimise la fonction, donc nous utilisons -F1\n",
    "\n",
    "# Utiliser l'algorithme TPE pour l'optimisation bayésienne\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20)\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres trouvés\n",
    "print(\"Meilleurs hyperparamètres:\", best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
