{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour lire les données de transcription\n",
    "def read_transcription(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Fonction pour lire les données du graphe de discours\n",
    "def read_discourse_graph(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = [line.strip().split() for line in file]\n",
    "\n",
    "    # Convertir les valeurs non numériques en indices numériques\n",
    "    data = [(int(start), relation, int(end)) if start.isdigit() and end.isdigit() else (start, relation, end) for start, relation, end in data]\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_dataframe(dialogue_id, transcription, discourse_graph, relation_dict, speaker_dict):\n",
    "    rows = []\n",
    "\n",
    "      # Iterate through all edges in the discourse graph\n",
    "    for edge in discourse_graph:\n",
    "        index_start, relation_type, index_end = edge\n",
    "\n",
    "        # Retrieve speaker information\n",
    "        speaker = transcription[index_start]['speaker']\n",
    "\n",
    "        # Convert relation type to integer using the dictionary\n",
    "        speaker_id = speaker_dict.get(speaker, -1)\n",
    "\n",
    "        # Retrieve the sentence\n",
    "        text = transcription[index_start]['text']\n",
    "\n",
    "        # Convert relation type to integer using the dictionary\n",
    "        relation_type_id = relation_dict.get(relation_type, -1)\n",
    "\n",
    "        # Add a row to the DataFrame\n",
    "        rows.append({\n",
    "            'dialogue_id': dialogue_id,\n",
    "            'index_start': index_start,\n",
    "            'text': text,\n",
    "            'index_end': index_end,\n",
    "            'speaker_type': speaker_id,\n",
    "            'speaker_text': speaker,\n",
    "            'relation_type': relation_type_id,\n",
    "            'relation_text': relation_type\n",
    "        })\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Fonction pour créer le dictionnaire de conversion des relations\n",
    "def create_relation_dict(discourse_graph):\n",
    "    relation_set = set()\n",
    "\n",
    "    # Collecter toutes les relations uniques\n",
    "    for edge in discourse_graph:\n",
    "        relation_set.add(edge[1])\n",
    "\n",
    "    # Créer un dictionnaire de conversion\n",
    "    relation_dict = {relation: idx for idx, relation in enumerate(relation_set)}\n",
    "\n",
    "    return relation_dict\n",
    "\n",
    "# Fonction pour créer le dictionnaire de conversion des speakers\n",
    "def create_speaker_dict(transcription):\n",
    "    speaker_set = set()\n",
    "\n",
    "    # Collecter tous les locuteurs uniques\n",
    "    for utterance in transcription:\n",
    "        speaker_set.add(utterance['speaker'])\n",
    "\n",
    "    # Créer un dictionnaire de conversion\n",
    "    speaker_dict = {speaker: idx for idx, speaker in enumerate(speaker_set)}\n",
    "\n",
    "    return speaker_dict\n",
    "\n",
    "def flatten(list_of_list):\n",
    "    return [item for sublist in list_of_list for item in sublist]\n",
    "\n",
    "# Function to get labels for a dialogue\n",
    "def get_label(dialogue_id, index,labels_data):\n",
    "    return labels_data.get(dialogue_id, [])[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacez 'votre_chemin' par le chemin correct\n",
    "path_train= Path(\"data/training\")\n",
    "path_test= Path(\"data/test\")\n",
    "\n",
    "# Remplacez 'vos_dialogue_ids' par votre liste réelle d'identifiants de dialogue\n",
    "dialogue_ids = ['ES2002', 'ES2005', 'ES2006', 'ES2007', 'ES2008', 'ES2009', 'ES2010', 'ES2012', 'ES2013', 'ES2015', 'ES2016', 'IS1000', 'IS1001', 'IS1002', 'IS1003', 'IS1004', 'IS1005', 'IS1006', 'IS1007', 'TS3005', 'TS3008', 'TS3009', 'TS3010', 'TS3011', 'TS3012']\n",
    "dialogue_ids = flatten([[m_id+s_id for s_id in 'abcd'] for m_id in dialogue_ids])\n",
    "dialogue_ids.remove('IS1002a')\n",
    "dialogue_ids.remove('IS1005d')\n",
    "dialogue_ids.remove('TS3012c')\n",
    "\n",
    "dialogue_ids_test = ['ES2003', 'ES2004', 'ES2011', 'ES2014', 'IS1008', 'IS1009', 'TS3003', 'TS3004', 'TS3006', 'TS3007']\n",
    "dialogue_ids_test = flatten([[m_id+s_id for s_id in 'abcd'] for m_id in dialogue_ids_test])\n",
    "\n",
    "# Liste pour stocker les DataFrames de chaque dialogue\n",
    "dfs = []\n",
    "dfs_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcourir chaque dialogue\n",
    "for dialogue_id in dialogue_ids:\n",
    "    # Lire les données de transcription et de graphe de discours\n",
    "    transcription = read_transcription(path_train / f'{dialogue_id}.json')\n",
    "    discourse_graph = read_discourse_graph(path_train / f'{dialogue_id}.txt')\n",
    "    \n",
    "    # Créer le dictionnaire de conversion des relations\n",
    "    relation_dict = create_relation_dict(discourse_graph)\n",
    "    speaker_dict = create_speaker_dict(transcription)\n",
    "\n",
    "    # Créer le DataFrame pour le dialogue actuel\n",
    "    df = create_dataframe(dialogue_id, transcription, discourse_graph, relation_dict, speaker_dict)\n",
    "    \n",
    "    # Ajouter le DataFrame à la liste\n",
    "    dfs.append(df)\n",
    "\n",
    "    # Ajouter la dernière phrase avec NaN pour index_end et 'relation'\n",
    "    last_utterance = transcription[-1]\n",
    "    last_speaker = last_utterance['speaker']\n",
    "    last_text = last_utterance['text']\n",
    "    last_row = {\n",
    "        'dialogue_id': dialogue_id,\n",
    "        'index_start': len(transcription) - 1,\n",
    "        'text': last_text,\n",
    "        'index_end': np.nan,\n",
    "        'speaker_type': speaker_dict.get(last_speaker, -1),\n",
    "        'speaker_text': last_speaker,\n",
    "        'relation_type': np.nan,\n",
    "        'relation_text': np.nan\n",
    "    }\n",
    "    dfs.append(pd.DataFrame([last_row]))\n",
    "\n",
    "# Parcourir chaque dialogue\n",
    "for dialogue_id in dialogue_ids_test:\n",
    "    # Lire les données de transcription et de graphe de discours\n",
    "    transcription = read_transcription(path_test / f'{dialogue_id}.json')\n",
    "    discourse_graph = read_discourse_graph(path_test / f'{dialogue_id}.txt')\n",
    "    \n",
    "    # Créer le dictionnaire de conversion des relations\n",
    "    relation_dict = create_relation_dict(discourse_graph)\n",
    "    speaker_dict = create_speaker_dict(transcription)\n",
    "\n",
    "    # Créer le DataFrame pour le dialogue actuel\n",
    "    df_test = create_dataframe(dialogue_id, transcription, discourse_graph, relation_dict, speaker_dict)\n",
    "    \n",
    "    # Ajouter le DataFrame à la liste\n",
    "    dfs_test.append(df_test)\n",
    "\n",
    "    # Ajouter la dernière phrase avec NaN pour index_end et 'relation'\n",
    "    last_utterance = transcription[-1]\n",
    "    last_speaker = last_utterance['speaker']\n",
    "    last_text = last_utterance['text']\n",
    "    last_row = {\n",
    "        'dialogue_id': dialogue_id,\n",
    "        'index_start': len(transcription) - 1,\n",
    "        'text': last_text,\n",
    "        'index_end': np.nan,\n",
    "        'speaker_type': speaker_dict.get(last_speaker, -1),\n",
    "        'speaker_text': last_speaker,\n",
    "        'relation_type': np.nan,\n",
    "        'relation_text': np.nan\n",
    "    }\n",
    "    dfs_test.append(pd.DataFrame([last_row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72623 entries, 0 to 72622\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   dialogue_id    72623 non-null  object \n",
      " 1   index_start    72623 non-null  int64  \n",
      " 2   text           72623 non-null  object \n",
      " 3   index_end      72526 non-null  float64\n",
      " 4   speaker_type   72623 non-null  int64  \n",
      " 5   speaker_text   72623 non-null  object \n",
      " 6   relation_type  72526 non-null  float64\n",
      " 7   relation_text  72526 non-null  object \n",
      " 8   label          72623 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 5.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue_id</th>\n",
       "      <th>index_start</th>\n",
       "      <th>text</th>\n",
       "      <th>index_end</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>speaker_text</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>relation_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>0</td>\n",
       "      <td>Okay</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>1</td>\n",
       "      <td>Right</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;vocalsound&gt; Um well this is the kick-off meet...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>3</td>\n",
       "      <td>Um &lt;vocalsound&gt; and um</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>4</td>\n",
       "      <td>this is just what we're gonna be doing over th...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dialogue_id  index_start                                               text  \\\n",
       "0     ES2002a            0                                               Okay   \n",
       "1     ES2002a            1                                              Right   \n",
       "2     ES2002a            2  <vocalsound> Um well this is the kick-off meet...   \n",
       "3     ES2002a            3                             Um <vocalsound> and um   \n",
       "4     ES2002a            4  this is just what we're gonna be doing over th...   \n",
       "\n",
       "   index_end  speaker_type speaker_text  relation_type relation_text  label  \n",
       "0        1.0             3           PM            4.0  Continuation      0  \n",
       "1        2.0             3           PM            4.0  Continuation      0  \n",
       "2        3.0             3           PM            5.0   Explanation      1  \n",
       "3        4.0             3           PM            3.0   Elaboration      0  \n",
       "4        5.0             3           PM            4.0  Continuation      0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concaténer tous les DataFrames en un seul\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df_test = pd.concat(dfs_test, ignore_index=True)\n",
    "\n",
    "with open(\"data/training_labels.json\", 'r') as file:\n",
    "    labels_data = json.load(file)\n",
    "\n",
    "df['label'] = df.apply(lambda row: get_label(row['dialogue_id'], row['index_start'], labels_data), axis=1)\n",
    "\n",
    "# Afficher le DataFrame final\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bert'] = df['text']\n",
    "for transcription_id in dialogue_ids:\n",
    "    bert_array = np.load('feature_bert/training/' + transcription_id + '.npy')\n",
    "    \n",
    "    # Obtenez les indices des lignes correspondant à la transcription_id\n",
    "    indices = df[df['dialogue_id'] == transcription_id].index\n",
    "    \n",
    "    # Remplacez les valeurs de la colonne 'text' par les valeurs de bert_array\n",
    "    for idx, value in enumerate(bert_array):\n",
    "        df.at[indices[idx-1], 'bert'] = value\n",
    "\n",
    "df_test['bert'] = df_test['text']\n",
    "for transcription_id in dialogue_ids_test:\n",
    "    bert_array_test = np.load('feature_bert/test/' + transcription_id + '.npy')\n",
    "    \n",
    "    # Obtenez les indices des lignes correspondant à la transcription_id\n",
    "    indices = df_test[df_test['dialogue_id'] == transcription_id].index\n",
    "    \n",
    "    # Remplacez les valeurs de la colonne 'text' par les valeurs de bert_array\n",
    "    for idx, value in enumerate(bert_array_test):\n",
    "        df_test.at[indices[idx-1], 'bert'] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'éléments dans chaque liste\n",
    "num_elements = len(df['bert'].iloc[0])\n",
    "\n",
    "# Créez de nouvelles colonnes pour chaque élément dans la liste\n",
    "new_columns = [f'coord_{i}' for i in range(num_elements)]\n",
    "\n",
    "# Appliquez une fonction qui divise chaque liste en plusieurs colonnes\n",
    "new_text_columns = df['bert'].apply(pd.Series)\n",
    "\n",
    "# Renommez les nouvelles colonnes avec les noms spécifiques\n",
    "new_text_columns.columns = new_columns\n",
    "\n",
    "# Concaténez les nouvelles colonnes avec le DataFrame existant\n",
    "df = pd.concat([df, new_text_columns], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Nombre d'éléments dans chaque liste\n",
    "num_elements = len(df_test['bert'].iloc[0])\n",
    "\n",
    "# Appliquez une fonction qui divise chaque liste en plusieurs colonnes\n",
    "new_text_columns_test = df_test['bert'].apply(pd.Series)\n",
    "\n",
    "# Renommez les nouvelles colonnes avec les noms spécifiques\n",
    "new_text_columns_test.columns = new_columns\n",
    "\n",
    "# Concaténez les nouvelles colonnes avec le DataFrame existant\n",
    "df_test = pd.concat([df_test, new_text_columns_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue_id</th>\n",
       "      <th>index_start</th>\n",
       "      <th>text</th>\n",
       "      <th>index_end</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>speaker_text</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>relation_text</th>\n",
       "      <th>bert</th>\n",
       "      <th>coord_0</th>\n",
       "      <th>...</th>\n",
       "      <th>coord_374</th>\n",
       "      <th>coord_375</th>\n",
       "      <th>coord_376</th>\n",
       "      <th>coord_377</th>\n",
       "      <th>coord_378</th>\n",
       "      <th>coord_379</th>\n",
       "      <th>coord_380</th>\n",
       "      <th>coord_381</th>\n",
       "      <th>coord_382</th>\n",
       "      <th>coord_383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>0</td>\n",
       "      <td>Okay , well</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>[-0.06684376, -0.10767134, 0.00158493, -0.0377...</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089991</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.015277</td>\n",
       "      <td>-0.003793</td>\n",
       "      <td>0.035303</td>\n",
       "      <td>0.063118</td>\n",
       "      <td>-0.012957</td>\n",
       "      <td>0.057301</td>\n",
       "      <td>-0.023757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>0</td>\n",
       "      <td>Okay , well</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>[-0.07298628, 0.052574955, -0.0014349254, -0.0...</td>\n",
       "      <td>-0.072986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084046</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>-0.011899</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>0.037757</td>\n",
       "      <td>0.123899</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.105005</td>\n",
       "      <td>0.098142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>2</td>\n",
       "      <td>Right ,</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Comment</td>\n",
       "      <td>[-0.069116786, -0.030909952, 0.07359838, -0.06...</td>\n",
       "      <td>-0.069117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>-0.056366</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.024899</td>\n",
       "      <td>-0.031351</td>\n",
       "      <td>-0.027805</td>\n",
       "      <td>0.029868</td>\n",
       "      <td>-0.065823</td>\n",
       "      <td>-0.027464</td>\n",
       "      <td>-0.058381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>3</td>\n",
       "      <td>my name's Adam Duguid ,</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[-0.08550309, -0.08060705, 0.04556774, 0.04994...</td>\n",
       "      <td>-0.085503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054002</td>\n",
       "      <td>0.058658</td>\n",
       "      <td>-0.060597</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>-0.028345</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.068747</td>\n",
       "      <td>0.050202</td>\n",
       "      <td>0.064570</td>\n",
       "      <td>0.009540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>4</td>\n",
       "      <td>we're here because of real reaction ,</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[-0.022576354, -0.028672846, -0.011893472, -0....</td>\n",
       "      <td>-0.022576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027556</td>\n",
       "      <td>0.016066</td>\n",
       "      <td>-0.029471</td>\n",
       "      <td>-0.008377</td>\n",
       "      <td>-0.026504</td>\n",
       "      <td>-0.055742</td>\n",
       "      <td>0.043690</td>\n",
       "      <td>-0.029209</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>-0.045938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31021</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1467</td>\n",
       "      <td>Okay , um hereby is &lt;disfmarker&gt; the meeting i...</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>3</td>\n",
       "      <td>ID</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Acknowledgement</td>\n",
       "      <td>[0.011373662, -0.05025587, -0.044846363, -0.06...</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007787</td>\n",
       "      <td>0.059220</td>\n",
       "      <td>0.039703</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>-0.015485</td>\n",
       "      <td>0.047069</td>\n",
       "      <td>-0.019950</td>\n",
       "      <td>0.070778</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>-0.014484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31022</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1468</td>\n",
       "      <td>&lt;vocalsound&gt; You declare . &lt;vocalsound&gt;</td>\n",
       "      <td>1469.0</td>\n",
       "      <td>0</td>\n",
       "      <td>ME</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Clarification_question</td>\n",
       "      <td>[-0.009817144, 0.014420933, 0.06607484, -0.006...</td>\n",
       "      <td>-0.009817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.032448</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.055542</td>\n",
       "      <td>-0.037788</td>\n",
       "      <td>-0.018767</td>\n",
       "      <td>0.070564</td>\n",
       "      <td>0.056986</td>\n",
       "      <td>0.057005</td>\n",
       "      <td>-0.008631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31023</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1469</td>\n",
       "      <td>I am the one who can say that . Yeah ?</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>[-0.029034479, 0.004965499, 0.001875145, 0.015...</td>\n",
       "      <td>-0.029034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010273</td>\n",
       "      <td>0.058479</td>\n",
       "      <td>0.044487</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>-0.023855</td>\n",
       "      <td>-0.010918</td>\n",
       "      <td>-0.039336</td>\n",
       "      <td>0.008305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31024</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1467</td>\n",
       "      <td>Okay , um hereby is &lt;disfmarker&gt; the meeting i...</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>3</td>\n",
       "      <td>ID</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Acknowledgement</td>\n",
       "      <td>[-0.14641145, 0.005653019, -0.009107485, -0.00...</td>\n",
       "      <td>-0.146411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115167</td>\n",
       "      <td>-0.042565</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>0.047295</td>\n",
       "      <td>0.097022</td>\n",
       "      <td>0.030912</td>\n",
       "      <td>0.091686</td>\n",
       "      <td>-0.034103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31025</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1471</td>\n",
       "      <td>Yeah .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.06921804, -0.06987868, 0.0041136686, -0.02...</td>\n",
       "      <td>-0.069218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069938</td>\n",
       "      <td>0.090868</td>\n",
       "      <td>0.014373</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>-0.092132</td>\n",
       "      <td>0.070056</td>\n",
       "      <td>0.038669</td>\n",
       "      <td>-0.028464</td>\n",
       "      <td>-0.046017</td>\n",
       "      <td>-0.013213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31026 rows × 393 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dialogue_id  index_start  \\\n",
       "0         ES2003a            0   \n",
       "1         ES2003a            0   \n",
       "2         ES2003a            2   \n",
       "3         ES2003a            3   \n",
       "4         ES2003a            4   \n",
       "...           ...          ...   \n",
       "31021     TS3007d         1467   \n",
       "31022     TS3007d         1468   \n",
       "31023     TS3007d         1469   \n",
       "31024     TS3007d         1467   \n",
       "31025     TS3007d         1471   \n",
       "\n",
       "                                                    text  index_end  \\\n",
       "0                                            Okay , well        1.0   \n",
       "1                                            Okay , well        2.0   \n",
       "2                                                Right ,        3.0   \n",
       "3                                my name's Adam Duguid ,        4.0   \n",
       "4                  we're here because of real reaction ,        5.0   \n",
       "...                                                  ...        ...   \n",
       "31021  Okay , um hereby is <disfmarker> the meeting i...     1468.0   \n",
       "31022            <vocalsound> You declare . <vocalsound>     1469.0   \n",
       "31023             I am the one who can say that . Yeah ?     1470.0   \n",
       "31024  Okay , um hereby is <disfmarker> the meeting i...     1471.0   \n",
       "31025                                             Yeah .        0.0   \n",
       "\n",
       "       speaker_type speaker_text  relation_type           relation_text  \\\n",
       "0                 3           PM            4.0            Continuation   \n",
       "1                 3           PM            4.0            Continuation   \n",
       "2                 3           PM            1.0                 Comment   \n",
       "3                 3           PM            5.0             Explanation   \n",
       "4                 3           PM            5.0             Explanation   \n",
       "...             ...          ...            ...                     ...   \n",
       "31021             3           ID           14.0         Acknowledgement   \n",
       "31022             0           ME           13.0  Clarification_question   \n",
       "31023             2           PM            4.0             Elaboration   \n",
       "31024             3           ID           14.0         Acknowledgement   \n",
       "31025             2           PM            0.0                       0   \n",
       "\n",
       "                                                    bert   coord_0  ...  \\\n",
       "0      [-0.06684376, -0.10767134, 0.00158493, -0.0377... -0.066844  ...   \n",
       "1      [-0.07298628, 0.052574955, -0.0014349254, -0.0... -0.072986  ...   \n",
       "2      [-0.069116786, -0.030909952, 0.07359838, -0.06... -0.069117  ...   \n",
       "3      [-0.08550309, -0.08060705, 0.04556774, 0.04994... -0.085503  ...   \n",
       "4      [-0.022576354, -0.028672846, -0.011893472, -0.... -0.022576  ...   \n",
       "...                                                  ...       ...  ...   \n",
       "31021  [0.011373662, -0.05025587, -0.044846363, -0.06...  0.011374  ...   \n",
       "31022  [-0.009817144, 0.014420933, 0.06607484, -0.006... -0.009817  ...   \n",
       "31023  [-0.029034479, 0.004965499, 0.001875145, 0.015... -0.029034  ...   \n",
       "31024  [-0.14641145, 0.005653019, -0.009107485, -0.00... -0.146411  ...   \n",
       "31025  [-0.06921804, -0.06987868, 0.0041136686, -0.02... -0.069218  ...   \n",
       "\n",
       "       coord_374  coord_375  coord_376  coord_377  coord_378  coord_379  \\\n",
       "0       0.089991   0.017770   0.004204   0.015277  -0.003793   0.035303   \n",
       "1       0.084046   0.017392  -0.011899   0.002536   0.007794   0.037757   \n",
       "2       0.057107  -0.056366   0.004875   0.024899  -0.031351  -0.027805   \n",
       "3       0.054002   0.058658  -0.060597   0.026250  -0.028345   0.014901   \n",
       "4       0.027556   0.016066  -0.029471  -0.008377  -0.026504  -0.055742   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "31021  -0.007787   0.059220   0.039703   0.081481  -0.015485   0.047069   \n",
       "31022   0.010156   0.032448   0.007771   0.055542  -0.037788  -0.018767   \n",
       "31023   0.010273   0.058479   0.044487  -0.000141  -0.047491   0.009351   \n",
       "31024   0.115167  -0.042565   0.024862   0.006545   0.066060   0.047295   \n",
       "31025   0.069938   0.090868   0.014373   0.039024  -0.092132   0.070056   \n",
       "\n",
       "       coord_380  coord_381  coord_382  coord_383  \n",
       "0       0.063118  -0.012957   0.057301  -0.023757  \n",
       "1       0.123899   0.037111   0.105005   0.098142  \n",
       "2       0.029868  -0.065823  -0.027464  -0.058381  \n",
       "3       0.068747   0.050202   0.064570   0.009540  \n",
       "4       0.043690  -0.029209   0.006706  -0.045938  \n",
       "...          ...        ...        ...        ...  \n",
       "31021  -0.019950   0.070778   0.025126  -0.014484  \n",
       "31022   0.070564   0.056986   0.057005  -0.008631  \n",
       "31023  -0.023855  -0.010918  -0.039336   0.008305  \n",
       "31024   0.097022   0.030912   0.091686  -0.034103  \n",
       "31025   0.038669  -0.028464  -0.046017  -0.013213  \n",
       "\n",
       "[31026 rows x 393 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(0)\n",
    "df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dif_start_end'] = df['index_end']-df['index_start']\n",
    "df['word_count'] = df['text'].apply(lambda x: len(x.split(' ')))\n",
    "df['nb_long_words'] = df['text'].apply(lambda x: sum(len(word) > 4 for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['dif_start_end'] = df_test['index_end']-df_test['index_start']\n",
    "df_test['word_count'] = df_test['text'].apply(lambda x: len(x.split(' ')))\n",
    "df_test['nb_long_words'] = df_test['text'].apply(lambda x: sum(len(word) > 4 for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue_id</th>\n",
       "      <th>index_start</th>\n",
       "      <th>text</th>\n",
       "      <th>index_end</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>speaker_text</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>relation_text</th>\n",
       "      <th>bert</th>\n",
       "      <th>coord_0</th>\n",
       "      <th>...</th>\n",
       "      <th>coord_377</th>\n",
       "      <th>coord_378</th>\n",
       "      <th>coord_379</th>\n",
       "      <th>coord_380</th>\n",
       "      <th>coord_381</th>\n",
       "      <th>coord_382</th>\n",
       "      <th>coord_383</th>\n",
       "      <th>dif_start_end</th>\n",
       "      <th>word_count</th>\n",
       "      <th>nb_long_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>0</td>\n",
       "      <td>Okay , well</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>[-0.06684376, -0.10767134, 0.00158493, -0.0377...</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015277</td>\n",
       "      <td>-0.003793</td>\n",
       "      <td>0.035303</td>\n",
       "      <td>0.063118</td>\n",
       "      <td>-0.012957</td>\n",
       "      <td>0.057301</td>\n",
       "      <td>-0.023757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>0</td>\n",
       "      <td>Okay , well</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>[-0.07298628, 0.052574955, -0.0014349254, -0.0...</td>\n",
       "      <td>-0.072986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>0.037757</td>\n",
       "      <td>0.123899</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.105005</td>\n",
       "      <td>0.098142</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>2</td>\n",
       "      <td>Right ,</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Comment</td>\n",
       "      <td>[-0.069116786, -0.030909952, 0.07359838, -0.06...</td>\n",
       "      <td>-0.069117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024899</td>\n",
       "      <td>-0.031351</td>\n",
       "      <td>-0.027805</td>\n",
       "      <td>0.029868</td>\n",
       "      <td>-0.065823</td>\n",
       "      <td>-0.027464</td>\n",
       "      <td>-0.058381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>3</td>\n",
       "      <td>my name's Adam Duguid ,</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[-0.08550309, -0.08060705, 0.04556774, 0.04994...</td>\n",
       "      <td>-0.085503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>-0.028345</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.068747</td>\n",
       "      <td>0.050202</td>\n",
       "      <td>0.064570</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>4</td>\n",
       "      <td>we're here because of real reaction ,</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[-0.022576354, -0.028672846, -0.011893472, -0....</td>\n",
       "      <td>-0.022576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008377</td>\n",
       "      <td>-0.026504</td>\n",
       "      <td>-0.055742</td>\n",
       "      <td>0.043690</td>\n",
       "      <td>-0.029209</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>-0.045938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31021</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1467</td>\n",
       "      <td>Okay , um hereby is &lt;disfmarker&gt; the meeting i...</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>3</td>\n",
       "      <td>ID</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Acknowledgement</td>\n",
       "      <td>[0.011373662, -0.05025587, -0.044846363, -0.06...</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>-0.015485</td>\n",
       "      <td>0.047069</td>\n",
       "      <td>-0.019950</td>\n",
       "      <td>0.070778</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>-0.014484</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31022</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1468</td>\n",
       "      <td>&lt;vocalsound&gt; You declare . &lt;vocalsound&gt;</td>\n",
       "      <td>1469.0</td>\n",
       "      <td>0</td>\n",
       "      <td>ME</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Clarification_question</td>\n",
       "      <td>[-0.009817144, 0.014420933, 0.06607484, -0.006...</td>\n",
       "      <td>-0.009817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055542</td>\n",
       "      <td>-0.037788</td>\n",
       "      <td>-0.018767</td>\n",
       "      <td>0.070564</td>\n",
       "      <td>0.056986</td>\n",
       "      <td>0.057005</td>\n",
       "      <td>-0.008631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31023</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1469</td>\n",
       "      <td>I am the one who can say that . Yeah ?</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>[-0.029034479, 0.004965499, 0.001875145, 0.015...</td>\n",
       "      <td>-0.029034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>-0.023855</td>\n",
       "      <td>-0.010918</td>\n",
       "      <td>-0.039336</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31024</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1467</td>\n",
       "      <td>Okay , um hereby is &lt;disfmarker&gt; the meeting i...</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>3</td>\n",
       "      <td>ID</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Acknowledgement</td>\n",
       "      <td>[-0.14641145, 0.005653019, -0.009107485, -0.00...</td>\n",
       "      <td>-0.146411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>0.047295</td>\n",
       "      <td>0.097022</td>\n",
       "      <td>0.030912</td>\n",
       "      <td>0.091686</td>\n",
       "      <td>-0.034103</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31025</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1471</td>\n",
       "      <td>Yeah .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.06921804, -0.06987868, 0.0041136686, -0.02...</td>\n",
       "      <td>-0.069218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>-0.092132</td>\n",
       "      <td>0.070056</td>\n",
       "      <td>0.038669</td>\n",
       "      <td>-0.028464</td>\n",
       "      <td>-0.046017</td>\n",
       "      <td>-0.013213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31026 rows × 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dialogue_id  index_start  \\\n",
       "0         ES2003a            0   \n",
       "1         ES2003a            0   \n",
       "2         ES2003a            2   \n",
       "3         ES2003a            3   \n",
       "4         ES2003a            4   \n",
       "...           ...          ...   \n",
       "31021     TS3007d         1467   \n",
       "31022     TS3007d         1468   \n",
       "31023     TS3007d         1469   \n",
       "31024     TS3007d         1467   \n",
       "31025     TS3007d         1471   \n",
       "\n",
       "                                                    text  index_end  \\\n",
       "0                                            Okay , well        1.0   \n",
       "1                                            Okay , well        2.0   \n",
       "2                                                Right ,        3.0   \n",
       "3                                my name's Adam Duguid ,        4.0   \n",
       "4                  we're here because of real reaction ,        5.0   \n",
       "...                                                  ...        ...   \n",
       "31021  Okay , um hereby is <disfmarker> the meeting i...     1468.0   \n",
       "31022            <vocalsound> You declare . <vocalsound>     1469.0   \n",
       "31023             I am the one who can say that . Yeah ?     1470.0   \n",
       "31024  Okay , um hereby is <disfmarker> the meeting i...     1471.0   \n",
       "31025                                             Yeah .        0.0   \n",
       "\n",
       "       speaker_type speaker_text  relation_type           relation_text  \\\n",
       "0                 3           PM            4.0            Continuation   \n",
       "1                 3           PM            4.0            Continuation   \n",
       "2                 3           PM            1.0                 Comment   \n",
       "3                 3           PM            5.0             Explanation   \n",
       "4                 3           PM            5.0             Explanation   \n",
       "...             ...          ...            ...                     ...   \n",
       "31021             3           ID           14.0         Acknowledgement   \n",
       "31022             0           ME           13.0  Clarification_question   \n",
       "31023             2           PM            4.0             Elaboration   \n",
       "31024             3           ID           14.0         Acknowledgement   \n",
       "31025             2           PM            0.0                       0   \n",
       "\n",
       "                                                    bert   coord_0  ...  \\\n",
       "0      [-0.06684376, -0.10767134, 0.00158493, -0.0377... -0.066844  ...   \n",
       "1      [-0.07298628, 0.052574955, -0.0014349254, -0.0... -0.072986  ...   \n",
       "2      [-0.069116786, -0.030909952, 0.07359838, -0.06... -0.069117  ...   \n",
       "3      [-0.08550309, -0.08060705, 0.04556774, 0.04994... -0.085503  ...   \n",
       "4      [-0.022576354, -0.028672846, -0.011893472, -0.... -0.022576  ...   \n",
       "...                                                  ...       ...  ...   \n",
       "31021  [0.011373662, -0.05025587, -0.044846363, -0.06...  0.011374  ...   \n",
       "31022  [-0.009817144, 0.014420933, 0.06607484, -0.006... -0.009817  ...   \n",
       "31023  [-0.029034479, 0.004965499, 0.001875145, 0.015... -0.029034  ...   \n",
       "31024  [-0.14641145, 0.005653019, -0.009107485, -0.00... -0.146411  ...   \n",
       "31025  [-0.06921804, -0.06987868, 0.0041136686, -0.02... -0.069218  ...   \n",
       "\n",
       "       coord_377  coord_378  coord_379  coord_380  coord_381  coord_382  \\\n",
       "0       0.015277  -0.003793   0.035303   0.063118  -0.012957   0.057301   \n",
       "1       0.002536   0.007794   0.037757   0.123899   0.037111   0.105005   \n",
       "2       0.024899  -0.031351  -0.027805   0.029868  -0.065823  -0.027464   \n",
       "3       0.026250  -0.028345   0.014901   0.068747   0.050202   0.064570   \n",
       "4      -0.008377  -0.026504  -0.055742   0.043690  -0.029209   0.006706   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "31021   0.081481  -0.015485   0.047069  -0.019950   0.070778   0.025126   \n",
       "31022   0.055542  -0.037788  -0.018767   0.070564   0.056986   0.057005   \n",
       "31023  -0.000141  -0.047491   0.009351  -0.023855  -0.010918  -0.039336   \n",
       "31024   0.006545   0.066060   0.047295   0.097022   0.030912   0.091686   \n",
       "31025   0.039024  -0.092132   0.070056   0.038669  -0.028464  -0.046017   \n",
       "\n",
       "       coord_383  dif_start_end  word_count  nb_long_words  \n",
       "0      -0.023757            1.0           3              0  \n",
       "1       0.098142            2.0           3              0  \n",
       "2      -0.058381            1.0           2              1  \n",
       "3       0.009540            1.0           5              2  \n",
       "4      -0.045938            1.0           7              3  \n",
       "...          ...            ...         ...            ...  \n",
       "31021  -0.014484            1.0          12              5  \n",
       "31022  -0.008631            1.0           5              3  \n",
       "31023   0.008305            1.0          11              0  \n",
       "31024  -0.034103            4.0          12              5  \n",
       "31025  -0.013213            0.0           2              0  \n",
       "\n",
       "[31026 rows x 396 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(0)\n",
    "df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['dialogue_id','text','speaker_text','relation_text','bert','label'],axis=1)\n",
    "y = df[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Ajuster la forme des données\n",
    "X_train = X_train.values.reshape(-1, len(X.columns))\n",
    "X_test = X_test.values.reshape(-1, len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\arnau\\OneDrive\\Documents\\Scolarité X\\3A\\INF554-AJA\\arnaud\\knNeighbourClassifier.ipynb Cell 15\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arnau/OneDrive/Documents/Scolarit%C3%A9%20X/3A/INF554-AJA/arnaud/knNeighbourClassifier.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m KNeighborsClassifier()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arnau/OneDrive/Documents/Scolarit%C3%A9%20X/3A/INF554-AJA/arnaud/knNeighbourClassifier.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#Train the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/arnau/OneDrive/Documents/Scolarit%C3%A9%20X/3A/INF554-AJA/arnaud/knNeighbourClassifier.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arnau/OneDrive/Documents/Scolarit%C3%A9%20X/3A/INF554-AJA/arnaud/knNeighbourClassifier.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#Predictions\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arnau/OneDrive/Documents/Scolarit%C3%A9%20X/3A/INF554-AJA/arnaud/knNeighbourClassifier.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neighbors\\_classification.py:233\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39m@_fit_context\u001b[39m(\n\u001b[0;32m    212\u001b[0m     \u001b[39m# KNeighborsClassifier.metric is not validated yet\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    214\u001b[0m )\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m    216\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \n\u001b[0;32m    218\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39m        The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 233\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neighbors\\_base.py:456\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    455\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[1;32m--> 456\u001b[0m         X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    457\u001b[0m             X, y, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    458\u001b[0m         )\n\u001b[0;32m    460\u001b[0m     \u001b[39mif\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m         \u001b[39m# Classification targets require a specific format\u001b[39;00m\n\u001b[0;32m    462\u001b[0m         \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1142\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[1;32m-> 1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1149\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1150\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1151\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1152\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1153\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1154\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1155\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1156\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1157\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1158\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m         )\n\u001b[0;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 957\u001b[0m         _assert_all_finite(\n\u001b[0;32m    958\u001b[0m             array,\n\u001b[0;32m    959\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    960\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    961\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    964\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    123\u001b[0m     X,\n\u001b[0;32m    124\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[0;32m    125\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[0;32m    126\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[0;32m    127\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    128\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    129\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nKNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Initialiser le modèle\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "#Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer le modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nRésultats du modèle :\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"F1-score: \", f1)\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "conf_df = pd.DataFrame(conf_matrix, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
    "\n",
    "print(\"\\nMatrice de confusion :\")\n",
    "print(conf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(['dialogue_id','text','speaker_text','relation_text','bert','label'],axis=1)\n",
    "y_train = df[['label']]\n",
    "X_test = df_test.drop(['dialogue_id','text','speaker_text','relation_text','bert'],axis=1)\n",
    "X_train = X_train.values.reshape(-1, X_train.shape[1])\n",
    "X_test = X_test.values.reshape(-1, X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Ajuster le modèle\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\arnau\\OneDrive\\Documents\\Scolarité X\\3A\\INF554-AJA\\arnaud\\DecisionTreeClassifier.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/arnau/OneDrive/Documents/Scolarit%C3%A9%20X/3A/INF554-AJA/arnaud/DecisionTreeClassifier.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arnau/OneDrive/Documents/Scolarit%C3%A9%20X/3A/INF554-AJA/arnaud/DecisionTreeClassifier.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39msum(test_pred))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arnau/OneDrive/Documents/Scolarit%C3%A9%20X/3A/INF554-AJA/arnaud/DecisionTreeClassifier.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39msum(y_test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "test_pred = clf.predict(X_test)\n",
    "print(np.sum(test_pred))\n",
    "print(np.sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un dictionnaire pour stocker les prédictions\n",
    "test_labels_final = {dialogue_id: [] for dialogue_id in dialogue_ids_test}\n",
    "\n",
    "# Parcourir les lignes de df_test\n",
    "for dialogue_id in dialogue_ids_test:\n",
    "    # Obtenez les indices des lignes correspondant au dialogue_id\n",
    "    indices = df_test[df_test['dialogue_id'] == dialogue_id].index\n",
    "    # Ajouter les valeurs de test_label[index] au dictionnaire\n",
    "    test_labels_final[dialogue_id] = test_pred[indices].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_labels_text_knc.json\", \"w\") as file:\n",
    "    json.dump(test_labels_final, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
