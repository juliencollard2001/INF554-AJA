{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour lire les données de transcription\n",
    "def read_transcription(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Fonction pour lire les données du graphe de discours\n",
    "def read_discourse_graph(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = [line.strip().split() for line in file]\n",
    "\n",
    "    # Convertir les valeurs non numériques en indices numériques\n",
    "    data = [(int(start), relation, int(end)) if start.isdigit() and end.isdigit() else (start, relation, end) for start, relation, end in data]\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_dataframe(dialogue_id, transcription, discourse_graph, relation_dict, speaker_dict):\n",
    "    rows = []\n",
    "\n",
    "      # Iterate through all edges in the discourse graph\n",
    "    for edge in discourse_graph:\n",
    "        index_start, relation_type, index_end = edge\n",
    "\n",
    "        # Retrieve speaker information\n",
    "        speaker = transcription[index_start]['speaker']\n",
    "\n",
    "        # Convert relation type to integer using the dictionary\n",
    "        speaker_id = speaker_dict.get(speaker, -1)\n",
    "\n",
    "        # Retrieve the sentence\n",
    "        text = transcription[index_start]['text']\n",
    "\n",
    "        # Convert relation type to integer using the dictionary\n",
    "        relation_type_id = relation_dict.get(relation_type, -1)\n",
    "\n",
    "        # Add a row to the DataFrame\n",
    "        rows.append({\n",
    "            'dialogue_id': dialogue_id,\n",
    "            'index_start': index_start,\n",
    "            'text': text,\n",
    "            'index_end': index_end,\n",
    "            'speaker_type': speaker_id,\n",
    "            'speaker_text': speaker,\n",
    "            'relation_type': relation_type_id,\n",
    "            'relation_text': relation_type\n",
    "        })\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Fonction pour créer le dictionnaire de conversion des relations\n",
    "def create_relation_dict(discourse_graph):\n",
    "    relation_set = set()\n",
    "\n",
    "    # Collecter toutes les relations uniques\n",
    "    for edge in discourse_graph:\n",
    "        relation_set.add(edge[1])\n",
    "\n",
    "    # Créer un dictionnaire de conversion\n",
    "    relation_dict = {relation: idx for idx, relation in enumerate(relation_set)}\n",
    "\n",
    "    return relation_dict\n",
    "\n",
    "# Fonction pour créer le dictionnaire de conversion des speakers\n",
    "def create_speaker_dict(transcription):\n",
    "    speaker_set = set()\n",
    "\n",
    "    # Collecter tous les locuteurs uniques\n",
    "    for utterance in transcription:\n",
    "        speaker_set.add(utterance['speaker'])\n",
    "\n",
    "    # Créer un dictionnaire de conversion\n",
    "    speaker_dict = {speaker: idx for idx, speaker in enumerate(speaker_set)}\n",
    "\n",
    "    return speaker_dict\n",
    "\n",
    "def flatten(list_of_list):\n",
    "    return [item for sublist in list_of_list for item in sublist]\n",
    "\n",
    "# Function to get labels for a dialogue\n",
    "def get_label(dialogue_id, index,labels_data):\n",
    "    return labels_data.get(dialogue_id, [])[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacez 'votre_chemin' par le chemin correct\n",
    "path_train= Path(\"data/training\")\n",
    "path_test= Path(\"data/test\")\n",
    "\n",
    "# Remplacez 'vos_dialogue_ids' par votre liste réelle d'identifiants de dialogue\n",
    "dialogue_ids = ['ES2002', 'ES2005', 'ES2006', 'ES2007', 'ES2008', 'ES2009', 'ES2010', 'ES2012', 'ES2013', 'ES2015', 'ES2016', 'IS1000', 'IS1001', 'IS1002', 'IS1003', 'IS1004', 'IS1005', 'IS1006', 'IS1007', 'TS3005', 'TS3008', 'TS3009', 'TS3010', 'TS3011', 'TS3012']\n",
    "dialogue_ids = flatten([[m_id+s_id for s_id in 'abcd'] for m_id in dialogue_ids])\n",
    "dialogue_ids.remove('IS1002a')\n",
    "dialogue_ids.remove('IS1005d')\n",
    "dialogue_ids.remove('TS3012c')\n",
    "\n",
    "dialogue_ids_test = ['ES2003', 'ES2004', 'ES2011', 'ES2014', 'IS1008', 'IS1009', 'TS3003', 'TS3004', 'TS3006', 'TS3007']\n",
    "dialogue_ids_test = flatten([[m_id+s_id for s_id in 'abcd'] for m_id in dialogue_ids_test])\n",
    "\n",
    "# Liste pour stocker les DataFrames de chaque dialogue\n",
    "dfs = []\n",
    "dfs_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcourir chaque dialogue\n",
    "for dialogue_id in dialogue_ids:\n",
    "    # Lire les données de transcription et de graphe de discours\n",
    "    transcription = read_transcription(path_train / f'{dialogue_id}.json')\n",
    "    discourse_graph = read_discourse_graph(path_train / f'{dialogue_id}.txt')\n",
    "    \n",
    "    # Créer le dictionnaire de conversion des relations\n",
    "    relation_dict = create_relation_dict(discourse_graph)\n",
    "    speaker_dict = create_speaker_dict(transcription)\n",
    "\n",
    "    # Créer le DataFrame pour le dialogue actuel\n",
    "    df = create_dataframe(dialogue_id, transcription, discourse_graph, relation_dict, speaker_dict)\n",
    "    \n",
    "    # Ajouter le DataFrame à la liste\n",
    "    dfs.append(df)\n",
    "\n",
    "    # Ajouter la dernière phrase avec NaN pour index_end et 'relation'\n",
    "    last_utterance = transcription[-1]\n",
    "    last_speaker = last_utterance['speaker']\n",
    "    last_text = last_utterance['text']\n",
    "    last_row = {\n",
    "        'dialogue_id': dialogue_id,\n",
    "        'index_start': len(transcription) - 1,\n",
    "        'text': last_text,\n",
    "        'index_end': np.nan,\n",
    "        'speaker_type': speaker_dict.get(last_speaker, -1),\n",
    "        'speaker_text': last_speaker,\n",
    "        'relation_type': np.nan,\n",
    "        'relation_text': np.nan\n",
    "    }\n",
    "    dfs.append(pd.DataFrame([last_row]))\n",
    "\n",
    "# Parcourir chaque dialogue\n",
    "for dialogue_id in dialogue_ids_test:\n",
    "    # Lire les données de transcription et de graphe de discours\n",
    "    transcription = read_transcription(path_test / f'{dialogue_id}.json')\n",
    "    discourse_graph = read_discourse_graph(path_test / f'{dialogue_id}.txt')\n",
    "    \n",
    "    # Créer le dictionnaire de conversion des relations\n",
    "    relation_dict = create_relation_dict(discourse_graph)\n",
    "    speaker_dict = create_speaker_dict(transcription)\n",
    "\n",
    "    # Créer le DataFrame pour le dialogue actuel\n",
    "    df_test = create_dataframe(dialogue_id, transcription, discourse_graph, relation_dict, speaker_dict)\n",
    "    \n",
    "    # Ajouter le DataFrame à la liste\n",
    "    dfs_test.append(df_test)\n",
    "\n",
    "    # Ajouter la dernière phrase avec NaN pour index_end et 'relation'\n",
    "    last_utterance = transcription[-1]\n",
    "    last_speaker = last_utterance['speaker']\n",
    "    last_text = last_utterance['text']\n",
    "    last_row = {\n",
    "        'dialogue_id': dialogue_id,\n",
    "        'index_start': len(transcription) - 1,\n",
    "        'text': last_text,\n",
    "        'index_end': np.nan,\n",
    "        'speaker_type': speaker_dict.get(last_speaker, -1),\n",
    "        'speaker_text': last_speaker,\n",
    "        'relation_type': np.nan,\n",
    "        'relation_text': np.nan\n",
    "    }\n",
    "    dfs_test.append(pd.DataFrame([last_row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72623 entries, 0 to 72622\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   dialogue_id    72623 non-null  object \n",
      " 1   index_start    72623 non-null  int64  \n",
      " 2   text           72623 non-null  object \n",
      " 3   index_end      72526 non-null  float64\n",
      " 4   speaker_type   72623 non-null  int64  \n",
      " 5   speaker_text   72623 non-null  object \n",
      " 6   relation_type  72526 non-null  float64\n",
      " 7   relation_text  72526 non-null  object \n",
      " 8   label          72623 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 5.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue_id</th>\n",
       "      <th>index_start</th>\n",
       "      <th>text</th>\n",
       "      <th>index_end</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>speaker_text</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>relation_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>0</td>\n",
       "      <td>Okay</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>1</td>\n",
       "      <td>Right</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;vocalsound&gt; Um well this is the kick-off meet...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>3</td>\n",
       "      <td>Um &lt;vocalsound&gt; and um</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>4</td>\n",
       "      <td>this is just what we're gonna be doing over th...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dialogue_id  index_start                                               text  \\\n",
       "0     ES2002a            0                                               Okay   \n",
       "1     ES2002a            1                                              Right   \n",
       "2     ES2002a            2  <vocalsound> Um well this is the kick-off meet...   \n",
       "3     ES2002a            3                             Um <vocalsound> and um   \n",
       "4     ES2002a            4  this is just what we're gonna be doing over th...   \n",
       "\n",
       "   index_end  speaker_type speaker_text  relation_type relation_text  label  \n",
       "0        1.0             2           PM            8.0  Continuation      0  \n",
       "1        2.0             2           PM            8.0  Continuation      0  \n",
       "2        3.0             2           PM            3.0   Explanation      1  \n",
       "3        4.0             2           PM            5.0   Elaboration      0  \n",
       "4        5.0             2           PM            8.0  Continuation      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concaténer tous les DataFrames en un seul\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df_test = pd.concat(dfs_test, ignore_index=True)\n",
    "\n",
    "with open(\"data/training_labels.json\", 'r') as file:\n",
    "    labels_data = json.load(file)\n",
    "\n",
    "df['label'] = df.apply(lambda row: get_label(row['dialogue_id'], row['index_start'], labels_data), axis=1)\n",
    "\n",
    "# Afficher le DataFrame final\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bert'] = df['text']\n",
    "for transcription_id in dialogue_ids:\n",
    "    bert_array = np.load('feature_bert/training/' + transcription_id + '.npy')\n",
    "    \n",
    "    # Obtenez les indices des lignes correspondant à la transcription_id\n",
    "    indices = df[df['dialogue_id'] == transcription_id].index\n",
    "    \n",
    "    # Remplacez les valeurs de la colonne 'text' par les valeurs de bert_array\n",
    "    for idx, value in enumerate(bert_array):\n",
    "        df.at[indices[idx-1], 'bert'] = value\n",
    "\n",
    "df_test['bert'] = df_test['text']\n",
    "for transcription_id in dialogue_ids_test:\n",
    "    bert_array_test = np.load('feature_bert/test/' + transcription_id + '.npy')\n",
    "    \n",
    "    # Obtenez les indices des lignes correspondant à la transcription_id\n",
    "    indices = df_test[df_test['dialogue_id'] == transcription_id].index\n",
    "    \n",
    "    # Remplacez les valeurs de la colonne 'text' par les valeurs de bert_array\n",
    "    for idx, value in enumerate(bert_array_test):\n",
    "        df_test.at[indices[idx-1], 'bert'] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'éléments dans chaque liste\n",
    "num_elements = len(df['bert'].iloc[0])\n",
    "\n",
    "# Créez de nouvelles colonnes pour chaque élément dans la liste\n",
    "new_columns = [f'coord_{i}' for i in range(num_elements)]\n",
    "\n",
    "# Appliquez une fonction qui divise chaque liste en plusieurs colonnes\n",
    "new_text_columns = df['bert'].apply(pd.Series)\n",
    "\n",
    "# Renommez les nouvelles colonnes avec les noms spécifiques\n",
    "new_text_columns.columns = new_columns\n",
    "\n",
    "# Concaténez les nouvelles colonnes avec le DataFrame existant\n",
    "df = pd.concat([df, new_text_columns], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Nombre d'éléments dans chaque liste\n",
    "num_elements = len(df_test['bert'].iloc[0])\n",
    "\n",
    "# Appliquez une fonction qui divise chaque liste en plusieurs colonnes\n",
    "new_text_columns_test = df_test['bert'].apply(pd.Series)\n",
    "\n",
    "# Renommez les nouvelles colonnes avec les noms spécifiques\n",
    "new_text_columns_test.columns = new_columns\n",
    "\n",
    "# Concaténez les nouvelles colonnes avec le DataFrame existant\n",
    "df_test = pd.concat([df_test, new_text_columns_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue_id</th>\n",
       "      <th>index_start</th>\n",
       "      <th>text</th>\n",
       "      <th>index_end</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>speaker_text</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>relation_text</th>\n",
       "      <th>bert</th>\n",
       "      <th>coord_0</th>\n",
       "      <th>...</th>\n",
       "      <th>coord_374</th>\n",
       "      <th>coord_375</th>\n",
       "      <th>coord_376</th>\n",
       "      <th>coord_377</th>\n",
       "      <th>coord_378</th>\n",
       "      <th>coord_379</th>\n",
       "      <th>coord_380</th>\n",
       "      <th>coord_381</th>\n",
       "      <th>coord_382</th>\n",
       "      <th>coord_383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>0</td>\n",
       "      <td>Okay , well</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>[-0.06684376, -0.10767134, 0.00158493, -0.0377...</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089991</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.015277</td>\n",
       "      <td>-0.003793</td>\n",
       "      <td>0.035303</td>\n",
       "      <td>0.063118</td>\n",
       "      <td>-0.012957</td>\n",
       "      <td>0.057301</td>\n",
       "      <td>-0.023757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>0</td>\n",
       "      <td>Okay , well</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>[-0.07298628, 0.052574955, -0.0014349254, -0.0...</td>\n",
       "      <td>-0.072986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084046</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>-0.011899</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>0.037757</td>\n",
       "      <td>0.123899</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.105005</td>\n",
       "      <td>0.098142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>2</td>\n",
       "      <td>Right ,</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Comment</td>\n",
       "      <td>[-0.069116786, -0.030909952, 0.07359838, -0.06...</td>\n",
       "      <td>-0.069117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>-0.056366</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.024899</td>\n",
       "      <td>-0.031351</td>\n",
       "      <td>-0.027805</td>\n",
       "      <td>0.029868</td>\n",
       "      <td>-0.065823</td>\n",
       "      <td>-0.027464</td>\n",
       "      <td>-0.058381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>3</td>\n",
       "      <td>my name's Adam Duguid ,</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[-0.08550309, -0.08060705, 0.04556774, 0.04994...</td>\n",
       "      <td>-0.085503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054002</td>\n",
       "      <td>0.058658</td>\n",
       "      <td>-0.060597</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>-0.028345</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.068747</td>\n",
       "      <td>0.050202</td>\n",
       "      <td>0.064570</td>\n",
       "      <td>0.009540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES2003a</td>\n",
       "      <td>4</td>\n",
       "      <td>we're here because of real reaction ,</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[-0.022576354, -0.028672846, -0.011893472, -0....</td>\n",
       "      <td>-0.022576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027556</td>\n",
       "      <td>0.016066</td>\n",
       "      <td>-0.029471</td>\n",
       "      <td>-0.008377</td>\n",
       "      <td>-0.026504</td>\n",
       "      <td>-0.055742</td>\n",
       "      <td>0.043690</td>\n",
       "      <td>-0.029209</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>-0.045938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31021</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1467</td>\n",
       "      <td>Okay , um hereby is &lt;disfmarker&gt; the meeting i...</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>3</td>\n",
       "      <td>ID</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Acknowledgement</td>\n",
       "      <td>[0.011373662, -0.05025587, -0.044846363, -0.06...</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007787</td>\n",
       "      <td>0.059220</td>\n",
       "      <td>0.039703</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>-0.015485</td>\n",
       "      <td>0.047069</td>\n",
       "      <td>-0.019950</td>\n",
       "      <td>0.070778</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>-0.014484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31022</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1468</td>\n",
       "      <td>&lt;vocalsound&gt; You declare . &lt;vocalsound&gt;</td>\n",
       "      <td>1469.0</td>\n",
       "      <td>0</td>\n",
       "      <td>ME</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Clarification_question</td>\n",
       "      <td>[-0.009817144, 0.014420933, 0.06607484, -0.006...</td>\n",
       "      <td>-0.009817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.032448</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.055542</td>\n",
       "      <td>-0.037788</td>\n",
       "      <td>-0.018767</td>\n",
       "      <td>0.070564</td>\n",
       "      <td>0.056986</td>\n",
       "      <td>0.057005</td>\n",
       "      <td>-0.008631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31023</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1469</td>\n",
       "      <td>I am the one who can say that . Yeah ?</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>[-0.029034479, 0.004965499, 0.001875145, 0.015...</td>\n",
       "      <td>-0.029034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010273</td>\n",
       "      <td>0.058479</td>\n",
       "      <td>0.044487</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>-0.023855</td>\n",
       "      <td>-0.010918</td>\n",
       "      <td>-0.039336</td>\n",
       "      <td>0.008305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31024</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1467</td>\n",
       "      <td>Okay , um hereby is &lt;disfmarker&gt; the meeting i...</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>3</td>\n",
       "      <td>ID</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Acknowledgement</td>\n",
       "      <td>[-0.14641145, 0.005653019, -0.009107485, -0.00...</td>\n",
       "      <td>-0.146411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115167</td>\n",
       "      <td>-0.042565</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>0.047295</td>\n",
       "      <td>0.097022</td>\n",
       "      <td>0.030912</td>\n",
       "      <td>0.091686</td>\n",
       "      <td>-0.034103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31025</th>\n",
       "      <td>TS3007d</td>\n",
       "      <td>1471</td>\n",
       "      <td>Yeah .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.06921804, -0.06987868, 0.0041136686, -0.02...</td>\n",
       "      <td>-0.069218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069938</td>\n",
       "      <td>0.090868</td>\n",
       "      <td>0.014373</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>-0.092132</td>\n",
       "      <td>0.070056</td>\n",
       "      <td>0.038669</td>\n",
       "      <td>-0.028464</td>\n",
       "      <td>-0.046017</td>\n",
       "      <td>-0.013213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31026 rows × 393 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dialogue_id  index_start  \\\n",
       "0         ES2003a            0   \n",
       "1         ES2003a            0   \n",
       "2         ES2003a            2   \n",
       "3         ES2003a            3   \n",
       "4         ES2003a            4   \n",
       "...           ...          ...   \n",
       "31021     TS3007d         1467   \n",
       "31022     TS3007d         1468   \n",
       "31023     TS3007d         1469   \n",
       "31024     TS3007d         1467   \n",
       "31025     TS3007d         1471   \n",
       "\n",
       "                                                    text  index_end  \\\n",
       "0                                            Okay , well        1.0   \n",
       "1                                            Okay , well        2.0   \n",
       "2                                                Right ,        3.0   \n",
       "3                                my name's Adam Duguid ,        4.0   \n",
       "4                  we're here because of real reaction ,        5.0   \n",
       "...                                                  ...        ...   \n",
       "31021  Okay , um hereby is <disfmarker> the meeting i...     1468.0   \n",
       "31022            <vocalsound> You declare . <vocalsound>     1469.0   \n",
       "31023             I am the one who can say that . Yeah ?     1470.0   \n",
       "31024  Okay , um hereby is <disfmarker> the meeting i...     1471.0   \n",
       "31025                                             Yeah .        0.0   \n",
       "\n",
       "       speaker_type speaker_text  relation_type           relation_text  \\\n",
       "0                 2           PM            9.0            Continuation   \n",
       "1                 2           PM            9.0            Continuation   \n",
       "2                 2           PM            6.0                 Comment   \n",
       "3                 2           PM            3.0             Explanation   \n",
       "4                 2           PM            3.0             Explanation   \n",
       "...             ...          ...            ...                     ...   \n",
       "31021             3           ID            8.0         Acknowledgement   \n",
       "31022             0           ME           13.0  Clarification_question   \n",
       "31023             2           PM            5.0             Elaboration   \n",
       "31024             3           ID            8.0         Acknowledgement   \n",
       "31025             2           PM            0.0                       0   \n",
       "\n",
       "                                                    bert   coord_0  ...  \\\n",
       "0      [-0.06684376, -0.10767134, 0.00158493, -0.0377... -0.066844  ...   \n",
       "1      [-0.07298628, 0.052574955, -0.0014349254, -0.0... -0.072986  ...   \n",
       "2      [-0.069116786, -0.030909952, 0.07359838, -0.06... -0.069117  ...   \n",
       "3      [-0.08550309, -0.08060705, 0.04556774, 0.04994... -0.085503  ...   \n",
       "4      [-0.022576354, -0.028672846, -0.011893472, -0.... -0.022576  ...   \n",
       "...                                                  ...       ...  ...   \n",
       "31021  [0.011373662, -0.05025587, -0.044846363, -0.06...  0.011374  ...   \n",
       "31022  [-0.009817144, 0.014420933, 0.06607484, -0.006... -0.009817  ...   \n",
       "31023  [-0.029034479, 0.004965499, 0.001875145, 0.015... -0.029034  ...   \n",
       "31024  [-0.14641145, 0.005653019, -0.009107485, -0.00... -0.146411  ...   \n",
       "31025  [-0.06921804, -0.06987868, 0.0041136686, -0.02... -0.069218  ...   \n",
       "\n",
       "       coord_374  coord_375  coord_376  coord_377  coord_378  coord_379  \\\n",
       "0       0.089991   0.017770   0.004204   0.015277  -0.003793   0.035303   \n",
       "1       0.084046   0.017392  -0.011899   0.002536   0.007794   0.037757   \n",
       "2       0.057107  -0.056366   0.004875   0.024899  -0.031351  -0.027805   \n",
       "3       0.054002   0.058658  -0.060597   0.026250  -0.028345   0.014901   \n",
       "4       0.027556   0.016066  -0.029471  -0.008377  -0.026504  -0.055742   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "31021  -0.007787   0.059220   0.039703   0.081481  -0.015485   0.047069   \n",
       "31022   0.010156   0.032448   0.007771   0.055542  -0.037788  -0.018767   \n",
       "31023   0.010273   0.058479   0.044487  -0.000141  -0.047491   0.009351   \n",
       "31024   0.115167  -0.042565   0.024862   0.006545   0.066060   0.047295   \n",
       "31025   0.069938   0.090868   0.014373   0.039024  -0.092132   0.070056   \n",
       "\n",
       "       coord_380  coord_381  coord_382  coord_383  \n",
       "0       0.063118  -0.012957   0.057301  -0.023757  \n",
       "1       0.123899   0.037111   0.105005   0.098142  \n",
       "2       0.029868  -0.065823  -0.027464  -0.058381  \n",
       "3       0.068747   0.050202   0.064570   0.009540  \n",
       "4       0.043690  -0.029209   0.006706  -0.045938  \n",
       "...          ...        ...        ...        ...  \n",
       "31021  -0.019950   0.070778   0.025126  -0.014484  \n",
       "31022   0.070564   0.056986   0.057005  -0.008631  \n",
       "31023  -0.023855  -0.010918  -0.039336   0.008305  \n",
       "31024   0.097022   0.030912   0.091686  -0.034103  \n",
       "31025   0.038669  -0.028464  -0.046017  -0.013213  \n",
       "\n",
       "[31026 rows x 393 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(0)\n",
    "df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue_id</th>\n",
       "      <th>index_start</th>\n",
       "      <th>text</th>\n",
       "      <th>index_end</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>speaker_text</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>relation_text</th>\n",
       "      <th>label</th>\n",
       "      <th>bert</th>\n",
       "      <th>...</th>\n",
       "      <th>coord_374</th>\n",
       "      <th>coord_375</th>\n",
       "      <th>coord_376</th>\n",
       "      <th>coord_377</th>\n",
       "      <th>coord_378</th>\n",
       "      <th>coord_379</th>\n",
       "      <th>coord_380</th>\n",
       "      <th>coord_381</th>\n",
       "      <th>coord_382</th>\n",
       "      <th>coord_383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>0</td>\n",
       "      <td>Okay</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PM</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Continuation</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.054861926, 0.047606602, -0.032625835, -0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092259</td>\n",
       "      <td>0.034839</td>\n",
       "      <td>-0.02149</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>0.027587</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.14595</td>\n",
       "      <td>0.037911</td>\n",
       "      <td>0.073511</td>\n",
       "      <td>0.079932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dialogue_id  index_start  text  index_end  speaker_type speaker_text  \\\n",
       "0     ES2002a            0  Okay        1.0             2           PM   \n",
       "\n",
       "   relation_type relation_text  label  \\\n",
       "0            8.0  Continuation      0   \n",
       "\n",
       "                                                bert  ...  coord_374  \\\n",
       "0  [-0.054861926, 0.047606602, -0.032625835, -0.0...  ...   0.092259   \n",
       "\n",
       "   coord_375  coord_376  coord_377  coord_378  coord_379  coord_380  \\\n",
       "0   0.034839   -0.02149   0.007297   0.027587   0.027128    0.14595   \n",
       "\n",
       "   coord_381  coord_382  coord_383  \n",
       "0   0.037911   0.073511   0.079932  \n",
       "\n",
       "[1 rows x 394 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Séparation en variables explicatives (X) et cible (y)\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with TF-IDF:\n",
      "Accuracy: 0.8882616179001721\n",
      "f1_score : 0.7188636757318553\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93     11009\n",
      "           1       0.92      0.59      0.72      3516\n",
      "\n",
      "    accuracy                           0.89     14525\n",
      "   macro avg       0.90      0.79      0.82     14525\n",
      "weighted avg       0.89      0.89      0.88     14525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report,f1_score\n",
    "\n",
    "# Création du pipeline avec TF-IDF et Random Forest\n",
    "model_rf_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model_rf_tfidf.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred_rf_tfidf = model_rf_tfidf.predict(X_test)\n",
    "\n",
    "# Évaluation du modèle\n",
    "print(\"Random Forest with TF-IDF:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf_tfidf))\n",
    "print(\"f1_score :\",f1_score(y_test,y_pred_rf_tfidf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = df.drop(['dialogue_id','text','speaker_text','relation_text','bert','label'],axis=1)\n",
    "#y_train = df[['label']]\n",
    "#X_test = df_test.drop(['dialogue_id','text','speaker_text','relation_text','bert'],axis=1)\n",
    "\n",
    "X_train = df['text']\n",
    "y_train = df['label']\n",
    "X_test = df_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;, RandomForestClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création du pipeline avec TF-IDF et Random Forest\n",
    "model_rf_tfidf2= Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model_rf_tfidf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2470\n"
     ]
    }
   ],
   "source": [
    "test_pred = model_rf_tfidf.predict(X_test)\n",
    "print(np.sum(test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un dictionnaire pour stocker les prédictions\n",
    "test_labels_final = {dialogue_id: [] for dialogue_id in dialogue_ids_test}\n",
    "\n",
    "# Parcourir les lignes de df_test\n",
    "for dialogue_id in dialogue_ids_test:\n",
    "    # Obtenez les indices des lignes correspondant au dialogue_id\n",
    "    indices = df_test[df_test['dialogue_id'] == dialogue_id].index\n",
    "    # Ajouter les valeurs de test_label[index] au dictionnaire\n",
    "    test_labels_final[dialogue_id] = test_pred[indices].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_labels_text_rf.json\", \"w\") as file:\n",
    "    json.dump(test_labels_final, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
