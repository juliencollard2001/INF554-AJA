{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f349936844ab48b3a0f92f2defb2e8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0325c8880d486bad9d4d52c1d3118c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e15a9b33238417ea0dc1bc15dbe8581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e568a9641445b09c1ce9c2765bca1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac42cfc67584776b51a703259f557c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acef6d9c232a4a6fa006cfff598b709d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8f311cb4d546f6a843061bc3fb158b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12b8ae1a5f04b6e8c92d182fa4df49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fece5a0b9f0647a5976541b711be144c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920cba81b9334d82b958d4b9ea77f98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2216a914a1743da8853179c4ee17462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b6c05090464ff9a6a286cc20cdd6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8496e3cb1e240c58c226c0af9374bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943d25cfca11419fae3528310444b7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def flatten(list_of_list):\n",
    "    return [item for sublist in list_of_list for item in sublist]\n",
    "\n",
    "path_to_training = Path(\"training\")\n",
    "path_to_test = Path(\"test\")\n",
    "\n",
    "#####\n",
    "# training and test sets of transcription ids\n",
    "#####\n",
    "training_set = ['ES2002', 'ES2005', 'ES2006', 'ES2007', 'ES2008', 'ES2009', 'ES2010', 'ES2012', 'ES2013', 'ES2015', 'ES2016', 'IS1000', 'IS1001', 'IS1002', 'IS1003', 'IS1004', 'IS1005', 'IS1006', 'IS1007', 'TS3005', 'TS3008', 'TS3009', 'TS3010', 'TS3011', 'TS3012']\n",
    "training_set = flatten([[m_id+s_id for s_id in 'abcd'] for m_id in training_set])\n",
    "training_set.remove('IS1002a')\n",
    "training_set.remove('IS1005d')\n",
    "training_set.remove('TS3012c')\n",
    "\n",
    "test_set = ['ES2003', 'ES2004', 'ES2011', 'ES2014', 'IS1008', 'IS1009', 'TS3003', 'TS3004', 'TS3006', 'TS3007']\n",
    "test_set = flatten([[m_id+s_id for s_id in 'abcd'] for m_id in test_set])\n",
    "\n",
    "\n",
    "#####\n",
    "# naive_baseline: all utterances are predicted important (label 1)\n",
    "#####\n",
    "test_labels = {}\n",
    "for transcription_id in test_set:\n",
    "    with open(path_to_test / f\"{transcription_id}.json\", \"r\") as file:\n",
    "        transcription = json.load(file)\n",
    "    \n",
    "    test_labels[transcription_id] = [1] * len(transcription)\n",
    "\n",
    "with open(\"test_labels_naive_baseline.json\", \"w\") as file:\n",
    "    json.dump(test_labels, file, indent=4)\n",
    "\n",
    "    #####\n",
    "# text_baseline: utterances are embedded with SentenceTransformer, then train a classifier.\n",
    "#####\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "y_training = []\n",
    "with open(\"training_labels.json\", \"r\") as file:\n",
    "    training_labels = json.load(file)\n",
    "X_training = []\n",
    "for transcription_id in training_set:\n",
    "    with open(path_to_training / f\"{transcription_id}.json\", \"r\") as file:\n",
    "        transcription = json.load(file)\n",
    "    \n",
    "    for utterance in transcription:\n",
    "        X_training.append(utterance[\"speaker\"] + \": \" + utterance[\"text\"])\n",
    "    \n",
    "    y_training += training_labels[transcription_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b39c157063645179f01096c88066f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X_training = bert.encode(X_training, show_progress_bar=True)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_training, y_training)\n",
    "\n",
    "test_labels = {}\n",
    "for transcription_id in test_set:\n",
    "    with open(path_to_test / f\"{transcription_id}.json\", \"r\") as file:\n",
    "        transcription = json.load(file)\n",
    "    \n",
    "    X_test = []\n",
    "    for utterance in transcription:\n",
    "        X_test.append(utterance[\"speaker\"] + \": \" + utterance[\"text\"])\n",
    "    \n",
    "    X_test = bert.encode(X_test)\n",
    "\n",
    "    y_test = clf.predict(X_test)\n",
    "    test_labels[transcription_id] = y_test.tolist()\n",
    "\n",
    "with open(\"test_labels_text_baseline.json\", \"w\") as file:\n",
    "    json.dump(test_labels, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
