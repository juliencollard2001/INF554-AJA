{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (1.26.1)\n",
      "Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: torch in /home/codespace/.local/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/codespace/.local/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torch-geometric in /usr/local/python/3.10.8/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.8/lib/python3.10/site-packages (from torch-geometric) (4.66.1)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from torch-geometric) (1.26.1)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from torch-geometric) (1.11.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /home/codespace/.local/lib/python3.10/site-packages (from torch-geometric) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.10/site-packages (from torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch-geometric) (5.9.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests->torch-geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->torch-geometric) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.8/lib/python3.10/site-packages (4.66.1)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: seaborn in /home/codespace/.local/lib/python3.10/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/codespace/.local/lib/python3.10/site-packages (from seaborn) (1.26.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/codespace/.local/lib/python3.10/site-packages (from seaborn) (2.1.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /home/codespace/.local/lib/python3.10/site-packages (from seaborn) (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install torch\n",
    "!pip install torch-geometric\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "import data_manipulation\n",
    "import model_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get all the available data into pandas dataframes\n",
    "# a bert embedding is also done for each node ie each sentence\n",
    "\n",
    "df_train_nodes, df_train_edges, df_test_nodes, df_test_edges = data_manipulation.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>line</th>\n",
       "      <th>speaker_int</th>\n",
       "      <th>speaker_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>bert_0</th>\n",
       "      <th>bert_1</th>\n",
       "      <th>bert_2</th>\n",
       "      <th>bert_3</th>\n",
       "      <th>...</th>\n",
       "      <th>bert_374</th>\n",
       "      <th>bert_375</th>\n",
       "      <th>bert_376</th>\n",
       "      <th>bert_377</th>\n",
       "      <th>bert_378</th>\n",
       "      <th>bert_379</th>\n",
       "      <th>bert_380</th>\n",
       "      <th>bert_381</th>\n",
       "      <th>bert_382</th>\n",
       "      <th>bert_383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PM</td>\n",
       "      <td>Okay</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.057809</td>\n",
       "      <td>-0.085828</td>\n",
       "      <td>-0.035720</td>\n",
       "      <td>-0.011185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018063</td>\n",
       "      <td>-0.033183</td>\n",
       "      <td>-0.004249</td>\n",
       "      <td>-0.026428</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>0.085386</td>\n",
       "      <td>-0.014607</td>\n",
       "      <td>0.058432</td>\n",
       "      <td>-0.009739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PM</td>\n",
       "      <td>Right</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.054862</td>\n",
       "      <td>0.047607</td>\n",
       "      <td>-0.032626</td>\n",
       "      <td>-0.010949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092259</td>\n",
       "      <td>0.034839</td>\n",
       "      <td>-0.021490</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>0.027587</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.145950</td>\n",
       "      <td>0.037911</td>\n",
       "      <td>0.073511</td>\n",
       "      <td>0.079932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>PM</td>\n",
       "      <td>&lt;vocalsound&gt; Um well this is the kick-off meet...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054665</td>\n",
       "      <td>-0.073837</td>\n",
       "      <td>-0.017161</td>\n",
       "      <td>-0.064276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035382</td>\n",
       "      <td>0.098955</td>\n",
       "      <td>-0.025984</td>\n",
       "      <td>0.077994</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.032260</td>\n",
       "      <td>0.022304</td>\n",
       "      <td>0.059096</td>\n",
       "      <td>-0.036019</td>\n",
       "      <td>-0.008820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>PM</td>\n",
       "      <td>Um &lt;vocalsound&gt; and um</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.010416</td>\n",
       "      <td>-0.072719</td>\n",
       "      <td>-0.017206</td>\n",
       "      <td>-0.088992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006533</td>\n",
       "      <td>0.032185</td>\n",
       "      <td>0.010955</td>\n",
       "      <td>0.041298</td>\n",
       "      <td>-0.018026</td>\n",
       "      <td>0.050856</td>\n",
       "      <td>0.007696</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>0.077368</td>\n",
       "      <td>-0.037393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>PM</td>\n",
       "      <td>this is just what we're gonna be doing over th...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028654</td>\n",
       "      <td>-0.015151</td>\n",
       "      <td>0.095910</td>\n",
       "      <td>-0.059113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108833</td>\n",
       "      <td>0.061266</td>\n",
       "      <td>-0.011521</td>\n",
       "      <td>-0.010543</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>0.117780</td>\n",
       "      <td>-0.017561</td>\n",
       "      <td>-0.028903</td>\n",
       "      <td>0.007401</td>\n",
       "      <td>-0.005552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 390 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  transcription  line  speaker_int speaker_text  \\\n",
       "0       ES2002a     0            0           PM   \n",
       "1       ES2002a     1            0           PM   \n",
       "2       ES2002a     2            0           PM   \n",
       "3       ES2002a     3            0           PM   \n",
       "4       ES2002a     4            0           PM   \n",
       "\n",
       "                                                text  label    bert_0  \\\n",
       "0                                               Okay      0 -0.057809   \n",
       "1                                              Right      0 -0.054862   \n",
       "2  <vocalsound> Um well this is the kick-off meet...      1 -0.054665   \n",
       "3                             Um <vocalsound> and um      0 -0.010416   \n",
       "4  this is just what we're gonna be doing over th...      0 -0.028654   \n",
       "\n",
       "     bert_1    bert_2    bert_3  ...  bert_374  bert_375  bert_376  bert_377  \\\n",
       "0 -0.085828 -0.035720 -0.011185  ...  0.018063 -0.033183 -0.004249 -0.026428   \n",
       "1  0.047607 -0.032626 -0.010949  ...  0.092259  0.034839 -0.021490  0.007297   \n",
       "2 -0.073837 -0.017161 -0.064276  ...  0.035382  0.098955 -0.025984  0.077994   \n",
       "3 -0.072719 -0.017206 -0.088992  ...  0.006533  0.032185  0.010955  0.041298   \n",
       "4 -0.015151  0.095910 -0.059113  ...  0.108833  0.061266 -0.011521 -0.010543   \n",
       "\n",
       "   bert_378  bert_379  bert_380  bert_381  bert_382  bert_383  \n",
       "0  0.074381  0.010209  0.085386 -0.014607  0.058432 -0.009739  \n",
       "1  0.027587  0.027128  0.145950  0.037911  0.073511  0.079932  \n",
       "2  0.003580  0.032260  0.022304  0.059096 -0.036019 -0.008820  \n",
       "3 -0.018026  0.050856  0.007696  0.041694  0.077368 -0.037393  \n",
       "4  0.010692  0.117780 -0.017561 -0.028903  0.007401 -0.005552  \n",
       "\n",
       "[5 rows x 390 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets visualize the data\n",
    "df_train_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type_int</th>\n",
       "      <th>type_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Continuation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Continuation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>Explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Continuation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transcription  start  end  type_int     type_text\n",
       "0       ES2002a      0    1         5  Continuation\n",
       "1       ES2002a      1    2         5  Continuation\n",
       "2       ES2002a      2    3        11   Explanation\n",
       "3       ES2002a      3    4         1   Elaboration\n",
       "4       ES2002a      4    5         5  Continuation"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets visualize the data\n",
    "df_train_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11214/148667591.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train_nodes['nb_onomatopoeias'] = df_train_nodes['text'].apply(lambda x: sum(x.split().count(mot) for mot in ['uh', 'um', 'okay', '<', 'ah', 'oh', 'yeah']))\n",
      "/tmp/ipykernel_11214/148667591.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test_nodes['nb_onomatopoeias'] = df_test_nodes['text'].apply(lambda x: sum(x.split().count(mot) for mot in ['uh', 'um', 'okay', '<', 'ah', 'oh', 'yeah']))\n"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# sentence length normalized\n",
    "df_train_nodes['sentence_length'] = df_train_nodes['text'].apply(lambda s: len(s.split()))\n",
    "df_train_nodes['sentence_length'] = scaler.fit_transform(df_train_nodes['sentence_length'].values.reshape(-1, 1))\n",
    "df_test_nodes['sentence_length'] = df_test_nodes['text'].apply(lambda s: len(s.split()))\n",
    "df_test_nodes['sentence_length'] = scaler.transform(df_test_nodes['sentence_length'].values.reshape(-1, 1))\n",
    "\n",
    "# Number of words with more than 7 letters\n",
    "df_train_nodes['nb_words_more_7'] = df_train_nodes['text'].apply(lambda x: sum(len(mot) > 7 and mot.lower() != '<vocalsound>' for mot in x.split()))\n",
    "df_train_nodes['nb_words_more_7'] = scaler.fit_transform(df_train_nodes['nb_words_more_7'].values.reshape(-1, 1))\n",
    "df_test_nodes['nb_words_more_7'] = df_test_nodes['text'].apply(lambda x: sum(len(mot) > 7 and mot.lower() != '<vocalsound>' for mot in x.split()))\n",
    "df_test_nodes['nb_words_more_7'] = scaler.transform(df_test_nodes['nb_words_more_7'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# speaker hot-one encoding\n",
    "one_hot_encoded = pd.get_dummies(df_train_nodes['speaker_int'], prefix='speaker', dtype=int)\n",
    "df_train_nodes = df_train_nodes.drop('speaker_int', axis=1)\n",
    "df_train_nodes = df_train_nodes.drop('speaker_text', axis=1)\n",
    "df_train_nodes = pd.concat([df_train_nodes, one_hot_encoded], axis=1)\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(df_test_nodes['speaker_int'], prefix='speaker', dtype=int)\n",
    "df_test_nodes = df_test_nodes.drop('speaker_int', axis=1)\n",
    "df_test_nodes = df_test_nodes.drop('speaker_text', axis=1)\n",
    "df_test_nodes = pd.concat([df_test_nodes, one_hot_encoded], axis=1)\n",
    "\n",
    "\n",
    "# TFIDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_train_nodes['text'])\n",
    "df_train_nodes['tfidf_sum'] = tfidf_matrix.sum(axis=1)\n",
    "df_train_nodes['tfidf_max'] = tfidf_matrix.max(axis=1).toarray().flatten()\n",
    "\n",
    "tfidf_matrix_test = tfidf_vectorizer.fit_transform(df_test_nodes['text'])\n",
    "df_test_nodes['tfidf_sum'] = tfidf_matrix_test.sum(axis=1)\n",
    "df_test_nodes['tfidf_max'] = tfidf_matrix_test.max(axis=1).toarray().flatten()\n",
    "\n",
    "# Normalization of TFIDF feature\n",
    "df_train_nodes['tfidf_sum'] = scaler.fit_transform(df_train_nodes['tfidf_sum'].values.reshape(-1,1))\n",
    "df_test_nodes['tfidf_sum'] = scaler.transform(df_test_nodes['tfidf_sum'].values.reshape(-1,1))\n",
    "\n",
    "df_train_nodes['tfidf_max'] = scaler.fit_transform(df_train_nodes['tfidf_max'].values.reshape(-1,1))\n",
    "df_test_nodes['tfidf_max'] = scaler.transform(df_test_nodes['tfidf_max'].values.reshape(-1,1))\n",
    "\n",
    "# Scaling Bert\n",
    "for i in range(384):\n",
    "    col_name = f'bert_{i}'\n",
    "    df_train_nodes[col_name] = scaler.fit_transform(df_train_nodes[col_name].values.reshape(-1, 1))\n",
    "    df_test_nodes[col_name] = scaler.transform(df_test_nodes[col_name].values.reshape(-1, 1))\n",
    "\n",
    "# onomatopoeias count\n",
    "df_train_nodes['nb_onomatopoeias'] = df_train_nodes['text'].apply(lambda x: sum(x.split().count(mot) for mot in ['uh', 'um', 'okay', '<', 'ah', 'oh', 'yeah']))\n",
    "df_train_nodes['nb_onomatopoeias'] = scaler.fit_transform(df_train_nodes['nb_onomatopoeias'].values.reshape(-1, 1))\n",
    "df_test_nodes['nb_onomatopoeias'] = df_test_nodes['text'].apply(lambda x: sum(x.split().count(mot) for mot in ['uh', 'um', 'okay', '<', 'ah', 'oh', 'yeah']))\n",
    "df_test_nodes['nb_onomatopoeias'] = scaler.transform(df_test_nodes['nb_onomatopoeias'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# dropping text\n",
    "df_train_nodes = df_train_nodes.drop('text', axis=1)\n",
    "df_test_nodes = df_test_nodes.drop('text', axis=1)\n",
    "\n",
    "# chanels 0-15 correspond to the original edges (direct direction for every link type)\n",
    "# we add chanels 16-31 that correspond to the reverse edges (reverse direction for every link type)\n",
    "\n",
    "new_df = pd.DataFrame({\n",
    "        'transcription': df_train_edges['transcription'],\n",
    "        'start': df_train_edges['end'],\n",
    "        'end': df_train_edges['start'],\n",
    "        'type_int': 16 + df_train_edges['type_int'],\n",
    "        'type_text': df_train_edges['type_text'] + \"_reverse\"\n",
    "    })\n",
    "df_train_edges = pd.concat([df_train_edges, new_df], ignore_index=True)\n",
    "\n",
    "new_df = pd.DataFrame({\n",
    "        'transcription': df_test_edges['transcription'],\n",
    "        'start': df_test_edges['end'],\n",
    "        'end': df_test_edges['start'],\n",
    "        'type_int': 16 + df_test_edges['type_int'],\n",
    "        'type_text': df_test_edges['type_text'] + \"_reverse\"\n",
    "    })\n",
    "df_test_edges = pd.concat([df_test_edges, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>line</th>\n",
       "      <th>label</th>\n",
       "      <th>bert_0</th>\n",
       "      <th>bert_1</th>\n",
       "      <th>bert_2</th>\n",
       "      <th>bert_3</th>\n",
       "      <th>bert_4</th>\n",
       "      <th>bert_5</th>\n",
       "      <th>bert_6</th>\n",
       "      <th>...</th>\n",
       "      <th>bert_383</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>nb_words_more_7</th>\n",
       "      <th>speaker_0</th>\n",
       "      <th>speaker_1</th>\n",
       "      <th>speaker_2</th>\n",
       "      <th>speaker_3</th>\n",
       "      <th>tfidf_sum</th>\n",
       "      <th>tfidf_max</th>\n",
       "      <th>nb_onomatopoeias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.322028</td>\n",
       "      <td>-1.528408</td>\n",
       "      <td>-0.774572</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.759986</td>\n",
       "      <td>-0.338124</td>\n",
       "      <td>0.537238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.353896</td>\n",
       "      <td>-1.008131</td>\n",
       "      <td>-0.647917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.168929</td>\n",
       "      <td>1.439285</td>\n",
       "      <td>-0.415549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.268435</td>\n",
       "      <td>1.241315</td>\n",
       "      <td>-0.697893</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>-0.996062</td>\n",
       "      <td>-0.923351</td>\n",
       "      <td>0.385835</td>\n",
       "      <td>...</td>\n",
       "      <td>1.772475</td>\n",
       "      <td>-1.008131</td>\n",
       "      <td>-0.647917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.168929</td>\n",
       "      <td>1.439285</td>\n",
       "      <td>-0.415549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.264855</td>\n",
       "      <td>-1.279508</td>\n",
       "      <td>-0.314608</td>\n",
       "      <td>-1.232834</td>\n",
       "      <td>-0.267942</td>\n",
       "      <td>1.443019</td>\n",
       "      <td>-1.093486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332110</td>\n",
       "      <td>0.789302</td>\n",
       "      <td>0.456915</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.228067</td>\n",
       "      <td>-0.927421</td>\n",
       "      <td>-0.415549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539704</td>\n",
       "      <td>-1.256303</td>\n",
       "      <td>-0.315716</td>\n",
       "      <td>-1.808670</td>\n",
       "      <td>-1.216124</td>\n",
       "      <td>1.208640</td>\n",
       "      <td>-0.446154</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.009652</td>\n",
       "      <td>-0.558773</td>\n",
       "      <td>-0.647917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.514793</td>\n",
       "      <td>0.709401</td>\n",
       "      <td>1.210442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208098</td>\n",
       "      <td>-0.061348</td>\n",
       "      <td>2.487742</td>\n",
       "      <td>-1.112549</td>\n",
       "      <td>0.396674</td>\n",
       "      <td>0.834525</td>\n",
       "      <td>-1.789326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254613</td>\n",
       "      <td>1.088874</td>\n",
       "      <td>-0.647917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.838146</td>\n",
       "      <td>-1.725435</td>\n",
       "      <td>-0.415549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  transcription  line  label    bert_0    bert_1    bert_2    bert_3  \\\n",
       "0       ES2002a     0      0 -0.322028 -1.528408 -0.774572  0.004107   \n",
       "1       ES2002a     1      0 -0.268435  1.241315 -0.697893  0.009600   \n",
       "2       ES2002a     2      1 -0.264855 -1.279508 -0.314608 -1.232834   \n",
       "3       ES2002a     3      0  0.539704 -1.256303 -0.315716 -1.808670   \n",
       "4       ES2002a     4      0  0.208098 -0.061348  2.487742 -1.112549   \n",
       "\n",
       "     bert_4    bert_5    bert_6  ...  bert_383  sentence_length  \\\n",
       "0  0.759986 -0.338124  0.537238  ... -0.353896        -1.008131   \n",
       "1 -0.996062 -0.923351  0.385835  ...  1.772475        -1.008131   \n",
       "2 -0.267942  1.443019 -1.093486  ... -0.332110         0.789302   \n",
       "3 -1.216124  1.208640 -0.446154  ... -1.009652        -0.558773   \n",
       "4  0.396674  0.834525 -1.789326  ... -0.254613         1.088874   \n",
       "\n",
       "   nb_words_more_7  speaker_0  speaker_1  speaker_2  speaker_3  tfidf_sum  \\\n",
       "0        -0.647917          1          0          0          0  -1.168929   \n",
       "1        -0.647917          1          0          0          0  -1.168929   \n",
       "2         0.456915          1          0          0          0   1.228067   \n",
       "3        -0.647917          1          0          0          0  -0.514793   \n",
       "4        -0.647917          1          0          0          0   1.838146   \n",
       "\n",
       "   tfidf_max  nb_onomatopoeias  \n",
       "0   1.439285         -0.415549  \n",
       "1   1.439285         -0.415549  \n",
       "2  -0.927421         -0.415549  \n",
       "3   0.709401          1.210442  \n",
       "4  -1.725435         -0.415549  \n",
       "\n",
       "[5 rows x 396 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets visualize extracted features\n",
    "df_train_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type_int</th>\n",
       "      <th>type_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Continuation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Continuation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>Explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES2002a</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Continuation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transcription  start  end  type_int     type_text\n",
       "0       ES2002a      0    1         5  Continuation\n",
       "1       ES2002a      1    2         5  Continuation\n",
       "2       ES2002a      2    3        11   Explanation\n",
       "3       ES2002a      3    4         1   Elaboration\n",
       "4       ES2002a      4    5         5  Continuation"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets visualize extracted features\n",
    "df_train_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features per node: 393\n",
      "Number of channels: 32\n"
     ]
    }
   ],
   "source": [
    "# lets transform the dataframes into pytorch geometric data objects\n",
    "\n",
    "# convert the dataframes into pytorch geometric data objects\n",
    "train_graphs, test_graphs = data_manipulation.make_graphs(df_train_nodes, df_train_edges, df_test_nodes, df_test_edges)\n",
    "\n",
    "N_features = train_graphs['ES2002a'].x.shape[1]\n",
    "N_chanels = len(train_graphs['ES2002a'].edge_index)\n",
    "print(\"Number of features per node: {}\".format(N_features))\n",
    "print(\"Number of channels: {}\".format(N_chanels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets split the train data into train and validation\n",
    "train_graphs, validation_graphs = data_manipulation.train_validation_split(train_graphs, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train graphs:  78\n",
      "number of validation graphs:  19\n",
      "number of test graphs:  40\n"
     ]
    }
   ],
   "source": [
    "print(\"number of train graphs: \", len(train_graphs))\n",
    "print(\"number of validation graphs: \", len(validation_graphs))\n",
    "print(\"number of test graphs: \", len(test_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 78 graphs, validating on 19 graphs\n",
      "- Epoch 001 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Epoch 002 -\n",
      "- Epoch 003 -\n",
      "Training finished !\n",
      "validation f1 score:  0.5229109113245345\n"
     ]
    }
   ],
   "source": [
    "# training and validation\n",
    "\n",
    "kappa = 6\n",
    "lr = 0.01\n",
    "nb_epochs = 3\n",
    "\n",
    "pytorch_model = model_definition.NodeClassifier(N_chanels, N_features)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([kappa]), reduction='mean')\n",
    "optimizer = torch.optim.Adam(pytorch_model.parameters(), lr=lr)\n",
    "\n",
    "model = model_definition.ModelWrapper(pytorch_model, criterion, optimizer)\n",
    "\n",
    "\n",
    "# training\n",
    "model.fit(train_graphs, validation_graphs, max_epochs=nb_epochs, verbose=1)\n",
    "\n",
    "# validation\n",
    "validation_f1_score  = model.score(validation_graphs)\n",
    "print(\"validation f1 score: \", validation_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score (out of the bag): 0.5492438021018607\n",
      "Model 2\n",
      "F1 score (out of the bag): 0.5281157006553542\n",
      "Model 3\n",
      "F1 score (out of the bag): 0.5790647730552669\n",
      "\n",
      "Validation f1 score with bagging:  0.5406856266361317\n"
     ]
    }
   ],
   "source": [
    "# bagging model\n",
    "\n",
    "bagging_models = []\n",
    "for _ in range(3):\n",
    "    kappa = 6\n",
    "    lr = 0.01\n",
    "    nb_epochs = 3\n",
    "    pytorch_model = model_definition.NodeClassifier(N_chanels, N_features)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([kappa]), reduction='mean')\n",
    "    optimizer = torch.optim.Adam(pytorch_model.parameters(), lr=lr)\n",
    "    model = model_definition.ModelWrapper(pytorch_model, criterion, optimizer)\n",
    "    bagging_models.append(model)\n",
    "\n",
    "bagging_model = model_definition.BaggingModel(bagging_models)\n",
    "\n",
    "# training\n",
    "bagging_model.fit(train_graphs, epochs=3, verbose=1)\n",
    "\n",
    "# validation\n",
    "f1 = bagging_model.score(validation_graphs)\n",
    "print('')\n",
    "print(\"Validation f1 score with bagging: \", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "F1 score (out of the bag): 0.5973205013354136\n",
      "Model 2\n",
      "F1 score (out of the bag): 0.5923413731605103\n",
      "Model 3\n",
      "F1 score (out of the bag): 0.5795302272678795\n",
      "Model 4\n",
      "F1 score (out of the bag): 0.5324012691735934\n",
      "Model 5\n",
      "F1 score (out of the bag): 0.5132476099366469\n"
     ]
    }
   ],
   "source": [
    "# training on all data and prediction\n",
    "\n",
    "bagging_models = []\n",
    "for _ in range(5):\n",
    "    kappa = 6\n",
    "    lr = 0.01\n",
    "    nb_epochs = 3\n",
    "    pytorch_model = model_definition.NodeClassifier(N_chanels, N_features)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([kappa]), reduction='mean')\n",
    "    optimizer = torch.optim.Adam(pytorch_model.parameters(), lr=lr)\n",
    "    model = model_definition.ModelWrapper(pytorch_model, criterion, optimizer)\n",
    "    bagging_models.append(model)\n",
    "\n",
    "bagging_model_final = model_definition.BaggingModel(bagging_models)\n",
    "\n",
    "# training on all data\n",
    "bagging_model_final.fit({**train_graphs, **validation_graphs}, epochs=3, verbose=1)\n",
    "\n",
    "# prediction\n",
    "prediction = bagging_model_final.predict(test_graphs)\n",
    "\n",
    "# submission\n",
    "data_manipulation.make_test_csv_submission_from_dict(prediction, 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
